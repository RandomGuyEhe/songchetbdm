{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3e21c8a",
   "metadata": {},
   "source": [
    "# Brain Stroke Detection from CT Scans using Deep Learning\n",
    "\n",
    "## Project Introduction\n",
    "\n",
    "This project aims to develop a deep learning-based system for the automatic detection of strokes in brain CT scans. Stroke is a medical emergency that requires immediate treatment to minimize brain damage and other complications. Early and accurate detection is crucial for improving patient outcomes.\n",
    "\n",
    "### Approach\n",
    "We will use an ensemble of three Convolutional Neural Networks (CNNs) pretrained on ImageNet:\n",
    "1. **DenseNet121** - Known for its dense connections that help with feature reuse and gradient flow\n",
    "2. **ResNet50** - Famous for its residual connections that solve the vanishing gradient problem\n",
    "3. **EfficientNet B3** - A model that uses compound scaling to balance network depth, width, and resolution\n",
    "\n",
    "Each model will be fine-tuned on our brain CT scan dataset. We then use an ensemble approach by averaging the predictions from all three models to make the final classification decision.\n",
    "\n",
    "### Dataset\n",
    "The dataset contains brain CT scan images organized into two classes:\n",
    "- **Normal**: CT scans of normal brains\n",
    "- **Stroke**: CT scans showing evidence of stroke\n",
    "\n",
    "The dataset is already split into Train, Validation, and Test sets.\n",
    "\n",
    "### Visualization\n",
    "For the detected stroke cases, we will use Gradient-weighted Class Activation Mapping (Grad-CAM) to highlight the areas of the brain that influenced the model's decision, providing an interpretable visual explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c1a8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import logging\n",
    "import pickle\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_curve, auc, confusion_matrix\n",
    "import random\n",
    "import time\n",
    "import timm\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"cnn_models_pytorch.log\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    logger.info(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    logger.info(\"Using CPU\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c12c89",
   "metadata": {},
   "source": [
    "## Dataset Definition\n",
    "\n",
    "First, we'll define our custom dataset class for brain CT scan images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c2a8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrainCTDataset(Dataset):\n",
    "    \"\"\"Custom Dataset for loading brain CT scan images\"\"\"\n",
    "    def __init__(self, directory, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            directory: Directory with all the images organized in class folders\n",
    "            transform: Optional transform to be applied on a sample\n",
    "        \"\"\"\n",
    "        self.directory = directory\n",
    "        self.transform = transform\n",
    "        self.classes = sorted([d for d in os.listdir(directory) if os.path.isdir(os.path.join(directory, d))])\n",
    "        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n",
    "        \n",
    "        self.samples = []\n",
    "        for class_name in self.classes:\n",
    "            class_dir = os.path.join(directory, class_name)\n",
    "            for img_name in os.listdir(class_dir):\n",
    "                if img_name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                    img_path = os.path.join(class_dir, img_name)\n",
    "                    self.samples.append((img_path, self.class_to_idx[class_name]))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        \n",
    "        try:\n",
    "            # Use PIL Image for compatibility with torchvision transforms\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            \n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            \n",
    "            return image, label\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading image {img_path}: {str(e)}\")\n",
    "            # Return a black image and the label on error\n",
    "            if self.transform:\n",
    "                default_img = torch.zeros((3, 256, 256))\n",
    "            else:\n",
    "                default_img = Image.new('RGB', (256, 256), (0, 0, 0))\n",
    "                if self.transform:\n",
    "                    default_img = self.transform(default_img)\n",
    "            return default_img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a43d81",
   "metadata": {},
   "source": [
    "## Data Visualization and Exploration\n",
    "\n",
    "Let's explore our dataset to understand its characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4d42a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataset directories\n",
    "base_dir = 'Brain_Stroke_CT-SCAN_image'\n",
    "train_dir = os.path.join(base_dir, 'Train')\n",
    "valid_dir = os.path.join(base_dir, 'Validation')\n",
    "test_dir = os.path.join(base_dir, 'Test')\n",
    "models_dir = 'models_pytorch'\n",
    "\n",
    "# Create models directory if it doesn't exist\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "# Function to count images by class\n",
    "def count_images(directory):\n",
    "    class_counts = {}\n",
    "    for class_name in os.listdir(directory):\n",
    "        class_dir = os.path.join(directory, class_name)\n",
    "        if os.path.isdir(class_dir):\n",
    "            count = len([f for f in os.listdir(class_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "            class_counts[class_name] = count\n",
    "    return class_counts\n",
    "\n",
    "# Count the number of images in each dataset split and class\n",
    "train_counts = count_images(train_dir)\n",
    "valid_counts = count_images(valid_dir)\n",
    "test_counts = count_images(test_dir)\n",
    "\n",
    "# Create a DataFrame for easier visualization\n",
    "counts_df = pd.DataFrame({\n",
    "    'Train': train_counts,\n",
    "    'Validation': valid_counts,\n",
    "    'Test': test_counts\n",
    "})\n",
    "\n",
    "print(\"Dataset Distribution:\")\n",
    "print(counts_df)\n",
    "\n",
    "# Visualize dataset distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "counts_df.plot(kind='bar', figsize=(10, 6))\n",
    "plt.title('Distribution of Classes Across Datasets')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.xlabel('Class')\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5512cfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some sample images from each class\n",
    "def display_samples(directory, num_samples=5):\n",
    "    \"\"\"Display sample images from each class\"\"\"\n",
    "    classes = sorted([d for d in os.listdir(directory) if os.path.isdir(os.path.join(directory, d))])\n",
    "    \n",
    "    plt.figure(figsize=(15, 8))\n",
    "    for i, class_name in enumerate(classes):\n",
    "        class_dir = os.path.join(directory, class_name)\n",
    "        images = [f for f in os.listdir(class_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        samples = random.sample(images, min(num_samples, len(images)))\n",
    "        \n",
    "        for j, img_name in enumerate(samples):\n",
    "            img_path = os.path.join(class_dir, img_name)\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            \n",
    "            plt.subplot(len(classes), num_samples, i * num_samples + j + 1)\n",
    "            plt.imshow(img)\n",
    "            plt.title(f\"{class_name}: {img_name}\")\n",
    "            plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Display sample images from training set\n",
    "print(\"Sample Training Images:\")\n",
    "display_samples(train_dir, num_samples=5)\n",
    "\n",
    "# Let's also check the image size of a random sample\n",
    "def check_image_stats(directory, num_samples=20):\n",
    "    \"\"\"Check image dimensions and aspect ratios\"\"\"\n",
    "    classes = sorted([d for d in os.listdir(directory) if os.path.isdir(os.path.join(directory, d))])\n",
    "    img_sizes = []\n",
    "    aspect_ratios = []\n",
    "    \n",
    "    for class_name in classes:\n",
    "        class_dir = os.path.join(directory, class_name)\n",
    "        images = [f for f in os.listdir(class_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        samples = random.sample(images, min(num_samples, len(images)))\n",
    "        \n",
    "        for img_name in samples:\n",
    "            img_path = os.path.join(class_dir, img_name)\n",
    "            img = Image.open(img_path)\n",
    "            width, height = img.size\n",
    "            img_sizes.append((width, height))\n",
    "            aspect_ratios.append(width / height)\n",
    "    \n",
    "    # Calculate statistics\n",
    "    widths = [w for w, h in img_sizes]\n",
    "    heights = [h for w, h in img_sizes]\n",
    "    \n",
    "    stats = {\n",
    "        'avg_width': np.mean(widths),\n",
    "        'avg_height': np.mean(heights),\n",
    "        'min_width': min(widths),\n",
    "        'min_height': min(heights),\n",
    "        'max_width': max(widths),\n",
    "        'max_height': max(heights),\n",
    "        'avg_aspect_ratio': np.mean(aspect_ratios)\n",
    "    }\n",
    "    \n",
    "    print(\"\\nImage Statistics:\")\n",
    "    for k, v in stats.items():\n",
    "        print(f\"{k}: {v:.2f}\")\n",
    "    \n",
    "    # Plot size distribution\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(widths, bins=10, alpha=0.7, label='Width')\n",
    "    plt.hist(heights, bins=10, alpha=0.7, label='Height')\n",
    "    plt.xlabel('Pixels')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Image Size Distribution')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(aspect_ratios, bins=10)\n",
    "    plt.xlabel('Aspect Ratio (Width/Height)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Aspect Ratio Distribution')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Check image statistics\n",
    "check_image_stats(train_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a77c89",
   "metadata": {},
   "source": [
    "## Model Definition and Training Utilities\n",
    "\n",
    "Now, let's define our model architecture and training utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34c59a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StrokeCTModel(nn.Module):\n",
    "    \"\"\"CNN model for stroke detection\"\"\"\n",
    "    def __init__(self, base_model_name, input_shape=(256, 256, 3), num_classes=2):\n",
    "        super(StrokeCTModel, self).__init__()\n",
    "        self.model_name = base_model_name.lower()\n",
    "        \n",
    "        # Initialize the base model\n",
    "        if self.model_name == 'densenet121':\n",
    "            self.base_model = models.densenet121(pretrained=True)\n",
    "            num_features = self.base_model.classifier.in_features\n",
    "            self.base_model.classifier = nn.Identity()\n",
    "            \n",
    "        elif self.model_name == 'resnet50':\n",
    "            self.base_model = models.resnet50(pretrained=True)\n",
    "            num_features = self.base_model.fc.in_features\n",
    "            self.base_model.fc = nn.Identity()\n",
    "            \n",
    "        elif self.model_name == 'efficientnet':\n",
    "            # Use timm for efficientnet models (more reliable)\n",
    "            import timm\n",
    "            # Use EfficientNet-B3 for better balance of performance and size\n",
    "            self.base_model = timm.create_model('efficientnet_b3', pretrained=True, num_classes=0)\n",
    "            num_features = self.base_model.num_features\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(f\"Unknown base model: {base_model_name}\")\n",
    "        \n",
    "        # Add custom layers\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(num_features, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1024, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        features = self.base_model(x)\n",
    "        return self.classifier(features)\n",
    "\n",
    "def create_model(base_model_name, input_shape=(256, 256, 3), num_classes=2):\n",
    "    \"\"\"\n",
    "    Create a CNN model using a pre-trained base model\n",
    "    \"\"\"\n",
    "    logger.info(f\"Creating {base_model_name} model...\")\n",
    "    model = StrokeCTModel(base_model_name, input_shape, num_classes)\n",
    "    model = model.to(device)\n",
    "    return model\n",
    "\n",
    "def get_transforms(is_training=False):\n",
    "    \"\"\"Get image transformations for training and testing\"\"\"\n",
    "    # Normalization values for ImageNet\n",
    "    normalize = transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "    \n",
    "    if is_training:\n",
    "        # Data augmentation for training\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(20),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "            transforms.RandomAffine(degrees=0, translate=(0.2, 0.2), scale=(0.8, 1.2)),\n",
    "            transforms.ToTensor(),\n",
    "            normalize\n",
    "        ])\n",
    "    else:\n",
    "        # Only resize and normalize for validation/testing\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.ToTensor(),\n",
    "            normalize\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a41fe22",
   "metadata": {},
   "source": [
    "## Training Function\n",
    "\n",
    "We'll define a function to train our models. We'll train each model for 50 epochs instead of the original 30 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ddb37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_dir, valid_dir, model_name, input_shape=(256, 256), batch_size=8, epochs=50):\n",
    "    \"\"\"\n",
    "    Enhanced training function with comprehensive metrics tracking\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : nn.Module\n",
    "        The PyTorch model to train\n",
    "    train_dir : str\n",
    "        Path to the training directory\n",
    "    valid_dir : str\n",
    "        Path to the validation directory\n",
    "    model_name : str\n",
    "        Name of the model for saving\n",
    "    input_shape : tuple\n",
    "        Input shape for images (width, height)\n",
    "    batch_size : int\n",
    "        Batch size for training\n",
    "    epochs : int\n",
    "        Number of epochs to train\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        The trained model and training history with extended metrics\n",
    "    \"\"\"\n",
    "    # Create datasets and data loaders\n",
    "    train_transform = get_transforms(is_training=True)\n",
    "    valid_transform = get_transforms(is_training=False)\n",
    "    \n",
    "    train_dataset = BrainCTDataset(train_dir, transform=train_transform)\n",
    "    valid_dataset = BrainCTDataset(valid_dir, transform=valid_transform)\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True, \n",
    "        num_workers=0, \n",
    "        pin_memory=False\n",
    "    )\n",
    "    \n",
    "    valid_loader = DataLoader(\n",
    "        valid_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False, \n",
    "        num_workers=0, \n",
    "        pin_memory=False\n",
    "    )\n",
    "    \n",
    "    logger.info(f\"Training samples: {len(train_dataset)}\")\n",
    "    logger.info(f\"Validation samples: {len(valid_dataset)}\")\n",
    "    \n",
    "    # Loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=5, verbose=True\n",
    "    )\n",
    "    \n",
    "    # Enhanced training history with additional metrics\n",
    "    history = {\n",
    "        'train_loss': [], 'train_acc': [], \n",
    "        'val_loss': [], 'val_acc': [],\n",
    "        # New metrics\n",
    "        'val_precision': [], 'val_recall': [], 'val_specificity': [], \n",
    "        'val_f1': [], 'val_g_mean': [], 'val_auc': []\n",
    "    }\n",
    "    \n",
    "    # Training loop\n",
    "    start_time = time.time()\n",
    "    best_val_metric = 0.0  # Can be set to val_acc, val_f1, etc.\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_start = time.time()\n",
    "        \n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        # For tracking detailed training metrics\n",
    "        all_train_preds = []\n",
    "        all_train_labels = []\n",
    "        all_train_probs = []\n",
    "        \n",
    "        train_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [Train]\")\n",
    "        for inputs, labels in train_bar:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Calculate probabilities and predictions\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            # Track metrics\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Store predictions and labels for detailed metrics\n",
    "            all_train_preds.extend(predicted.cpu().numpy())\n",
    "            all_train_labels.extend(labels.cpu().numpy())\n",
    "            all_train_probs.extend(probs.cpu().numpy())\n",
    "            \n",
    "            # Update progress bar\n",
    "            train_bar.set_postfix({\n",
    "                'loss': f\"{loss.item():.4f}\",\n",
    "                'acc': f\"{train_correct/train_total:.4f}\"\n",
    "            })\n",
    "        \n",
    "        # Calculate epoch-level training metrics\n",
    "        train_loss = train_loss / len(train_loader.dataset)\n",
    "        train_acc = train_correct / train_total\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        \n",
    "        # Tracking for validation metrics\n",
    "        all_val_preds = []\n",
    "        all_val_labels = []\n",
    "        all_val_probs = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            val_bar = tqdm(valid_loader, desc=f\"Epoch {epoch+1}/{epochs} [Valid]\")\n",
    "            for inputs, labels in val_bar:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                # Calculate probabilities and predictions\n",
    "                probs = F.softmax(outputs, dim=1)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                \n",
    "                # Store for metrics calculation\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                all_val_preds.extend(predicted.cpu().numpy())\n",
    "                all_val_labels.extend(labels.cpu().numpy())\n",
    "                all_val_probs.extend(probs.cpu().numpy())\n",
    "                \n",
    "                # Update progress bar with basic metrics\n",
    "                val_correct = sum(1 for p, l in zip(all_val_preds, all_val_labels) if p == l)\n",
    "                val_total = len(all_val_labels)\n",
    "                val_bar.set_postfix({\n",
    "                    'loss': f\"{loss.item():.4f}\",\n",
    "                    'acc': f\"{val_correct/val_total:.4f}\"\n",
    "                })\n",
    "        \n",
    "        # Process validation metrics\n",
    "        val_loss = val_loss / len(valid_loader.dataset)\n",
    "        \n",
    "        # Convert to numpy arrays for metric calculations\n",
    "        y_true = np.array(all_val_labels)\n",
    "        y_pred = np.array(all_val_preds)\n",
    "        y_prob = np.array([probs[1] for probs in all_val_probs])  # Assuming binary with class 1 as positive\n",
    "        \n",
    "        # Calculate validation metrics (using scikit-learn)\n",
    "        val_acc = accuracy_score(y_true, y_pred)\n",
    "        try:\n",
    "            # Confusion matrix for binary classification\n",
    "            tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "            \n",
    "            # Calculate metrics\n",
    "            val_precision = precision_score(y_true, y_pred)\n",
    "            val_recall = recall_score(y_true, y_pred)  # Same as sensitivity\n",
    "            val_sensitivity = val_recall\n",
    "            val_specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "            val_f1 = f1_score(y_true, y_pred)\n",
    "            val_g_mean = np.sqrt(val_sensitivity * val_specificity)\n",
    "            \n",
    "            # Calculate AUC\n",
    "            val_auc = roc_auc_score(y_true, y_prob)\n",
    "            \n",
    "            # Update history with all metrics\n",
    "            history['val_precision'].append(val_precision)\n",
    "            history['val_recall'].append(val_recall)\n",
    "            history['val_specificity'].append(val_specificity)\n",
    "            history['val_f1'].append(val_f1)\n",
    "            history['val_g_mean'].append(val_g_mean)\n",
    "            history['val_auc'].append(val_auc)\n",
    "            \n",
    "            # Decide which metric to use for best model selection\n",
    "            val_metric = val_f1  # Could use val_acc, val_g_mean, etc.\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Error calculating validation metrics: {str(e)}\")\n",
    "            # Fallback to accuracy if something goes wrong\n",
    "            val_metric = val_acc\n",
    "            val_precision = val_recall = val_specificity = val_f1 = val_g_mean = val_auc = 0\n",
    "        \n",
    "        # Update standard metrics in history\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # Calculate epoch time\n",
    "        epoch_time = time.time() - epoch_start\n",
    "        \n",
    "        # Print comprehensive epoch statistics\n",
    "        logger.info(f\"Epoch {epoch+1}/{epochs} - \"\n",
    "                   f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
    "                   f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, \"\n",
    "                   f\"Val Precision: {val_precision:.4f}, Val Recall: {val_recall:.4f}, \"\n",
    "                   f\"Val Specificity: {val_specificity:.4f}, Val F1: {val_f1:.4f}, \"\n",
    "                   f\"Val G-Mean: {val_g_mean:.4f}, Val AUC: {val_auc:.4f} - \"\n",
    "                   f\"Time: {epoch_time:.2f}s\")\n",
    "        \n",
    "        # Save the best model based on chosen metric\n",
    "        if val_metric > best_val_metric:\n",
    "            best_val_metric = val_metric\n",
    "            best_model_path = os.path.join(models_dir, f\"stroke_{model_name}_best.pkl\")\n",
    "            \n",
    "            # Save model to CPU before pickling\n",
    "            model_cpu = model.cpu()\n",
    "            with open(best_model_path, 'wb') as f:\n",
    "                pickle.dump(model_cpu, f)\n",
    "                \n",
    "            # Move model back to device\n",
    "            model = model.to(device)\n",
    "            logger.info(f\"Best model saved to {best_model_path} with validation metric: {best_val_metric:.4f}\")\n",
    "    \n",
    "    # Calculate total training time\n",
    "    total_time = time.time() - start_time\n",
    "    logger.info(f\"Training completed in {total_time:.2f}s\")\n",
    "    \n",
    "    # Save final model\n",
    "    final_model_path = os.path.join(models_dir, f\"stroke_{model_name}.pkl\")\n",
    "    \n",
    "    # Save model to CPU before pickling\n",
    "    model_cpu = model.cpu()\n",
    "    with open(final_model_path, 'wb') as f:\n",
    "        pickle.dump(model_cpu, f)\n",
    "        \n",
    "    # Move model back to device for any further operations\n",
    "    model = model.to(device)\n",
    "    logger.info(f\"Final model saved to {final_model_path}\")\n",
    "    \n",
    "    # Save training history\n",
    "    history_path = os.path.join(models_dir, f\"{model_name}_history.pkl\")\n",
    "    with open(history_path, 'wb') as f:\n",
    "        pickle.dump(history, f)\n",
    "    logger.info(f\"Training history saved to {history_path}\")\n",
    "    \n",
    "    # Create enhanced training visualization\n",
    "    visualize_training_history(history, model_name, models_dir)\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "def visualize_training_history(history, model_name, output_dir):\n",
    "    \"\"\"\n",
    "    Visualize training history with all metrics\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    history : dict\n",
    "        Dictionary containing training and validation metrics\n",
    "    model_name : str\n",
    "        Name of the model for display and saving\n",
    "    output_dir : str\n",
    "        Directory to save visualizations\n",
    "    \"\"\"\n",
    "    # Create figure for training/validation metrics\n",
    "    num_metrics = 4\n",
    "    fig, axes = plt.subplots(num_metrics, 2, figsize=(15, 5*num_metrics))\n",
    "    \n",
    "    # Plot accuracy and loss\n",
    "    axes[0, 0].plot(history['train_acc'], label='Train')\n",
    "    axes[0, 0].plot(history['val_acc'], label='Validation')\n",
    "    axes[0, 0].set_title(f'{model_name.upper()} - Accuracy')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Accuracy')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[0, 1].plot(history['train_loss'], label='Train')\n",
    "    axes[0, 1].plot(history['val_loss'], label='Validation')\n",
    "    axes[0, 1].set_title(f'{model_name.upper()} - Loss')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Loss')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot precision and recall\n",
    "    if 'val_precision' in history and history['val_precision']:\n",
    "        axes[1, 0].plot(history['val_precision'], label='Precision')\n",
    "        axes[1, 0].plot(history['val_recall'], label='Recall')\n",
    "        axes[1, 0].set_title(f'{model_name.upper()} - Precision & Recall')\n",
    "        axes[1, 0].set_xlabel('Epoch')\n",
    "        axes[1, 0].set_ylabel('Score')\n",
    "        axes[1, 0].legend()\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot F1 score\n",
    "        axes[1, 1].plot(history['val_f1'], label='F1 Score')\n",
    "        axes[1, 1].set_title(f'{model_name.upper()} - F1 Score')\n",
    "        axes[1, 1].set_xlabel('Epoch')\n",
    "        axes[1, 1].set_ylabel('F1 Score')\n",
    "        axes[1, 1].legend()\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot specificity and G-mean\n",
    "        axes[2, 0].plot(history['val_specificity'], label='Specificity')\n",
    "        axes[2, 0].set_title(f'{model_name.upper()} - Specificity')\n",
    "        axes[2, 0].set_xlabel('Epoch')\n",
    "        axes[2, 0].set_ylabel('Specificity')\n",
    "        axes[2, 0].legend()\n",
    "        axes[2, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        axes[2, 1].plot(history['val_g_mean'], label='G-Mean')\n",
    "        axes[2, 1].set_title(f'{model_name.upper()} - G-Mean')\n",
    "        axes[2, 1].set_xlabel('Epoch')\n",
    "        axes[2, 1].set_ylabel('G-Mean')\n",
    "        axes[2, 1].legend()\n",
    "        axes[2, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot AUC\n",
    "        axes[3, 0].plot(history['val_auc'], label='AUC')\n",
    "        axes[3, 0].set_title(f'{model_name.upper()} - AUC')\n",
    "        axes[3, 0].set_xlabel('Epoch')\n",
    "        axes[3, 0].set_ylabel('AUC')\n",
    "        axes[3, 0].legend()\n",
    "        axes[3, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot all metrics together for comparison\n",
    "        axes[3, 1].plot(history['val_acc'], label='Accuracy')\n",
    "        axes[3, 1].plot(history['val_precision'], label='Precision')\n",
    "        axes[3, 1].plot(history['val_recall'], label='Recall')\n",
    "        axes[3, 1].plot(history['val_specificity'], label='Specificity')\n",
    "        axes[3, 1].plot(history['val_f1'], label='F1')\n",
    "        axes[3, 1].plot(history['val_g_mean'], label='G-Mean')\n",
    "        axes[3, 1].plot(history['val_auc'], label='AUC')\n",
    "        axes[3, 1].set_title(f'{model_name.upper()} - All Metrics')\n",
    "        axes[3, 1].set_xlabel('Epoch')\n",
    "        axes[3, 1].set_ylabel('Score')\n",
    "        axes[3, 1].legend(loc='lower right')\n",
    "        axes[3, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, f\"{model_name}_training_metrics.png\"), dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Create a final metrics summary\n",
    "    if 'val_precision' in history and history['val_precision']:\n",
    "        best_epoch = np.argmax(history['val_f1'])  # Could use different metric for best epoch\n",
    "        \n",
    "        # Create a metrics summary table\n",
    "        metrics = {\n",
    "            'Accuracy': history['val_acc'][best_epoch],\n",
    "            'Precision': history['val_precision'][best_epoch],\n",
    "            'Recall/Sensitivity': history['val_recall'][best_epoch],\n",
    "            'Specificity': history['val_specificity'][best_epoch],\n",
    "            'F1 Score': history['val_f1'][best_epoch],\n",
    "            'G-Mean': history['val_g_mean'][best_epoch],\n",
    "            'AUC': history['val_auc'][best_epoch]\n",
    "        }\n",
    "        \n",
    "        # Create and save metrics summary plot\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.bar(metrics.keys(), metrics.values(), color='steelblue')\n",
    "        plt.title(f'{model_name.upper()} - Best Validation Metrics (Epoch {best_epoch+1})')\n",
    "        plt.ylabel('Score')\n",
    "        plt.ylim(0, 1.1)\n",
    "        \n",
    "        # Add the values on top of the bars\n",
    "        for i, (metric, value) in enumerate(metrics.items()):\n",
    "            plt.text(i, value + 0.05, f\"{value:.4f}\", ha='center')\n",
    "            \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, f\"{model_name}_best_metrics.png\"), dpi=150, bbox_inches='tight')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe8af27",
   "metadata": {},
   "source": [
    "## Training Models\n",
    "\n",
    "We'll train each model separately with 50 epochs. You can run one model at a time and come back later to run the next model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7462a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_densenet121():\n",
    "    \"\"\"Train DenseNet121 model for stroke detection\"\"\"\n",
    "    logger.info(\"Training DENSENET121 model...\")\n",
    "    # DenseNet121 has efficient memory usage due to feature reuse, can handle larger batch size\n",
    "    # and may benefit from longer training\n",
    "    model = create_model('densenet121')\n",
    "    model, history = train_model(\n",
    "        model, \n",
    "        train_dir, \n",
    "        valid_dir, \n",
    "        'densenet121', \n",
    "        batch_size=16,  # Batch size 16 is feasible for 4GB VRAM. Scale appropriately based on your GPU memory\n",
    "        epochs=60       # More epochs for better feature learning\n",
    "    )\n",
    "    return model, history\n",
    "\n",
    "# Uncomment to train DenseNet121\n",
    "# densenet_model, densenet_history = train_densenet121()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f4b93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_resnet50():\n",
    "    \"\"\"Train ResNet50 model for stroke detection\"\"\"\n",
    "    logger.info(\"Training RESNET50 model...\")\n",
    "    # ResNet50 has moderate memory requirements\n",
    "    model = create_model('resnet50')\n",
    "    model, history = train_model(\n",
    "        model, \n",
    "        train_dir, \n",
    "        valid_dir, \n",
    "        'resnet50', \n",
    "        batch_size=24,  # Batch size 24 is feasible for 4GB VRAM. Scale appropriately based on your GPU memory\n",
    "        epochs=50       # Standard number of epochs\n",
    "    )\n",
    "    return model, history\n",
    "\n",
    "# Uncomment to train ResNet50\n",
    "# resnet_model, resnet_history = train_resnet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b257e3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_efficientnet():\n",
    "    \"\"\"Train EfficientNet model for stroke detection\"\"\"\n",
    "    logger.info(\"Training EFFICIENTNET model...\")\n",
    "    # EfficientNet models are more complex and memory-intensive\n",
    "    model = create_model('efficientnet')\n",
    "    model, history = train_model(\n",
    "        model, \n",
    "        train_dir, \n",
    "        valid_dir, \n",
    "        'efficientnet', \n",
    "        batch_size=12,   # Batch size 12 is feasible for 4GB VRAM. Scale appropriately based on your GPU memory\n",
    "        epochs=40       # Fewer epochs as it tends to converge faster\n",
    "    )\n",
    "    return model, history\n",
    "\n",
    "# Uncomment to train EfficientNet\n",
    "efficientnet_model, efficientnet_history = train_efficientnet()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cff6a5",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "We'll implement functions to evaluate our models on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cb1fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_name):\n",
    "    \"\"\"Load a trained model from disk\"\"\"\n",
    "    model_path = os.path.join(models_dir, f\"stroke_{model_name}.pkl\")\n",
    "    if os.path.exists(model_path):\n",
    "        logger.info(f\"Loading {model_name} model from {model_path}\")\n",
    "        try:\n",
    "            with open(model_path, 'rb') as f:\n",
    "                model = pickle.load(f).to(device)\n",
    "            model.eval()\n",
    "            logger.info(f\"Successfully loaded {model_name} model\")\n",
    "            return model\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading {model_name} model: {str(e)}\")\n",
    "            return None\n",
    "    else:\n",
    "        logger.error(f\"Model file not found: {model_path}\")\n",
    "        return None\n",
    "    \n",
    "def evaluate_model(model, test_dir, input_shape=(256, 256), batch_size=16):\n",
    "    \"\"\"Evaluate a model on the test set\"\"\"\n",
    "    # Create dataset and data loader\n",
    "    test_transform = get_transforms(is_training=False)\n",
    "    test_dataset = BrainCTDataset(test_dir, transform=test_transform)\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False, \n",
    "        num_workers=0,\n",
    "        pin_memory=False\n",
    "    )\n",
    "    \n",
    "    logger.info(f\"Test samples: {len(test_dataset)}\")\n",
    "    \n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Initialize variables\n",
    "    test_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    \n",
    "    # Loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Evaluate the model\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Get predictions and probabilities\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            # Save predictions, probabilities, and labels\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            \n",
    "            # Update loss\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "    \n",
    "    # Calculate average loss\n",
    "    test_loss = test_loss / len(test_loader.dataset)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = np.mean(np.array(all_preds) == np.array(all_labels))\n",
    "    \n",
    "    # Create result dictionary\n",
    "    result = {\n",
    "        'loss': test_loss,\n",
    "        'accuracy': accuracy,\n",
    "        'predictions': all_preds,\n",
    "        'labels': all_labels,\n",
    "        'probabilities': all_probs\n",
    "    }\n",
    "    \n",
    "    # Calculate confusion matrix and classification report\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    class_names = test_dataset.classes\n",
    "    report = classification_report(all_labels, all_preds, target_names=class_names, output_dict=True)\n",
    "    \n",
    "    result['confusion_matrix'] = cm\n",
    "    result['classification_report'] = report\n",
    "    \n",
    "    return result\n",
    "\n",
    "def visualize_evaluation(result, model_name):\n",
    "    \"\"\"Visualize evaluation results\"\"\"\n",
    "    # Print evaluation metrics\n",
    "    print(f\"Model: {model_name.upper()}\")\n",
    "    \n",
    "    # Print loss if available (for individual models)\n",
    "    if 'loss' in result:\n",
    "        print(f\"Test Loss: {result['loss']:.4f}\")\n",
    "    else:\n",
    "        print(f\"Test Loss: N/A (not calculated for ensemble)\")\n",
    "    \n",
    "    print(f\"Test Accuracy: {result['accuracy']:.4f}\")\n",
    "    \n",
    "    # Print classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    report_df = pd.DataFrame(result['classification_report']).transpose()\n",
    "    print(report_df)\n",
    "    \n",
    "    # Visualize confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    cm = result['confusion_matrix']\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Normal', 'Stroke'], \n",
    "                yticklabels=['Normal', 'Stroke'])\n",
    "    plt.title(f'Confusion Matrix - {model_name.upper()}')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f723f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate each model\n",
    "models = ['densenet121', 'resnet50', 'efficientnet']\n",
    "evaluation_results = {}\n",
    "\n",
    "for model_name in models:\n",
    "    model = load_model(model_name)\n",
    "    if model is not None:\n",
    "        result = evaluate_model(model, test_dir)\n",
    "        evaluation_results[model_name] = result\n",
    "        visualize_evaluation(result, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a2e99e",
   "metadata": {},
   "source": [
    "## Ensemble Model Evaluation\n",
    "\n",
    "Let's evaluate the performance of the ensemble model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fc7dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ensemble(evaluation_results, test_dir):\n",
    "    \"\"\"Evaluate the ensemble of models\"\"\"\n",
    "    # Ensure we have results for all models\n",
    "    models = ['densenet121', 'resnet50', 'efficientnet']\n",
    "    available_models = [model for model in models if model in evaluation_results]\n",
    "    \n",
    "    if not available_models:\n",
    "        logger.error(\"No model evaluation results available.\")\n",
    "        return None\n",
    "    \n",
    "    # Get the test dataset labels\n",
    "    test_transform = get_transforms(is_training=False)\n",
    "    test_dataset = BrainCTDataset(test_dir, transform=test_transform)\n",
    "    \n",
    "    # Get a reference model for labels\n",
    "    ref_model = available_models[0]\n",
    "    \n",
    "    # Combine predictions from all models\n",
    "    ensemble_probs = np.zeros((len(evaluation_results[ref_model]['labels']), 2))\n",
    "    for model_name in available_models:\n",
    "        ensemble_probs += np.array(evaluation_results[model_name]['probabilities'])\n",
    "    \n",
    "    # Average the probabilities\n",
    "    ensemble_probs /= len(available_models)\n",
    "    \n",
    "    # Get the predicted classes\n",
    "    ensemble_preds = np.argmax(ensemble_probs, axis=1)\n",
    "    true_labels = evaluation_results[ref_model]['labels']\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(true_labels, ensemble_preds)\n",
    "    \n",
    "    # Calculate confusion matrix and classification report\n",
    "    cm = confusion_matrix(true_labels, ensemble_preds)\n",
    "    class_names = test_dataset.classes\n",
    "    report = classification_report(true_labels, ensemble_preds, target_names=class_names, output_dict=True)\n",
    "    \n",
    "    # Create result dictionary\n",
    "    result = {\n",
    "        'accuracy': accuracy,\n",
    "        'predictions': ensemble_preds,\n",
    "        'labels': true_labels,\n",
    "        'probabilities': ensemble_probs,\n",
    "        'confusion_matrix': cm,\n",
    "        'classification_report': report\n",
    "    }\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Evaluate the ensemble model\n",
    "ensemble_result = evaluate_ensemble(evaluation_results, test_dir)\n",
    "if ensemble_result is not None:\n",
    "    visualize_evaluation(ensemble_result, 'ensemble')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adb0bc7",
   "metadata": {},
   "source": [
    "## Model Explanation with Grad-CAM\n",
    "\n",
    "Now, let's implement Grad-CAM for model interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c8b5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradCAM:\n",
    "    \"\"\"Class for generating Grad-CAM visualizations\"\"\"\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.hooks = []\n",
    "        \n",
    "        # Register hooks\n",
    "        self.hooks.append(self.target_layer.register_forward_hook(self.save_activation))\n",
    "        self.hooks.append(self.target_layer.register_full_backward_hook(self.save_gradient))\n",
    "        \n",
    "        self.activations = None\n",
    "        self.gradients = None\n",
    "    \n",
    "    def save_activation(self, module, input, output):\n",
    "        self.activations = output.detach()\n",
    "    \n",
    "    def save_gradient(self, module, grad_input, grad_output):\n",
    "        self.gradients = grad_output[0].detach()\n",
    "    \n",
    "    def __call__(self, x, class_idx=None):\n",
    "        # Ensure model is in evaluation mode\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Forward pass\n",
    "        x = x.to(device)\n",
    "        output = self.model(x)\n",
    "        \n",
    "        # If class_idx is None, use the class with the highest score\n",
    "        if class_idx is None:\n",
    "            class_idx = torch.argmax(output, dim=1).item()\n",
    "        \n",
    "        # Zero gradients\n",
    "        self.model.zero_grad()\n",
    "        \n",
    "        # Target for backprop\n",
    "        one_hot = torch.zeros_like(output)\n",
    "        one_hot[0, class_idx] = 1\n",
    "        \n",
    "        # Backward pass\n",
    "        output.backward(gradient=one_hot, retain_graph=True)\n",
    "        \n",
    "        # Average gradients globally\n",
    "        weights = torch.mean(self.gradients, dim=(2, 3))\n",
    "        \n",
    "        # Create weighted activation map\n",
    "        batch_size, n_channels, h, w = self.activations.size()\n",
    "        cam = torch.zeros((h, w), dtype=torch.float32, device=device)\n",
    "        \n",
    "        for i, w in enumerate(weights[0]):\n",
    "            cam += w * self.activations[0, i]\n",
    "        \n",
    "        # Apply ReLU\n",
    "        cam = torch.clamp(cam, min=0)\n",
    "        \n",
    "        # Normalize\n",
    "        if torch.max(cam) > 0:\n",
    "            cam = cam / torch.max(cam)\n",
    "        \n",
    "        # Convert to numpy and resize\n",
    "        cam = cam.cpu().numpy()\n",
    "        \n",
    "        # Remove hooks\n",
    "        for hook in self.hooks:\n",
    "            hook.remove()\n",
    "        \n",
    "        return cam\n",
    "\n",
    "def get_target_layer(model):\n",
    "    \"\"\"Get the target layer for GradCAM based on model architecture\"\"\"\n",
    "    if model.model_name == 'densenet121':\n",
    "        return model.base_model.features.denseblock4.denselayer16.conv2\n",
    "    elif model.model_name == 'resnet50':\n",
    "        return model.base_model.layer4[-1].conv3\n",
    "    elif model.model_name == 'efficientnet':\n",
    "        # For timm EfficientNet models\n",
    "        if hasattr(model.base_model, 'conv_head'):\n",
    "            return model.base_model.conv_head\n",
    "        # Fallback option - find the last convolutional layer\n",
    "        for name, module in reversed(list(model.base_model.named_modules())):\n",
    "            if isinstance(module, nn.Conv2d):\n",
    "                return module\n",
    "    \n",
    "    # If we can't find any suitable layer, raise error\n",
    "    raise ValueError(f\"Could not identify a suitable convolutional layer for GradCAM in {model.model_name}\")\n",
    "\n",
    "def generate_gradcam(img, model):\n",
    "    \"\"\"Generate a GradCAM heatmap for the image\"\"\"\n",
    "    # Convert numpy array to tensor if needed\n",
    "    if isinstance(img, np.ndarray):\n",
    "        img = torch.from_numpy(img.transpose((2, 0, 1))).float().unsqueeze(0)\n",
    "    elif isinstance(img, torch.Tensor) and img.dim() == 3:\n",
    "        img = img.unsqueeze(0)\n",
    "    \n",
    "    # Get target layer\n",
    "    target_layer = get_target_layer(model)\n",
    "    \n",
    "    # Create GradCAM\n",
    "    grad_cam = GradCAM(model, target_layer)\n",
    "    \n",
    "    # Generate heatmap\n",
    "    heatmap = grad_cam(img)\n",
    "    \n",
    "    # Resize to match input size\n",
    "    if isinstance(img, torch.Tensor):\n",
    "        h, w = img.shape[2:]\n",
    "    else:\n",
    "        h, w = img.shape[:2]\n",
    "    \n",
    "    heatmap = cv2.resize(heatmap, (w, h))\n",
    "    \n",
    "    return heatmap\n",
    "\n",
    "def superimpose_heatmap(img, heatmap, alpha=0.6):\n",
    "    \"\"\"Superimpose a heatmap on the original image\"\"\"\n",
    "    # Convert heatmap to RGB\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "    \n",
    "    # Convert original image to uint8 if it's not already\n",
    "    if isinstance(img, torch.Tensor):\n",
    "        img = img.cpu().numpy().transpose(1, 2, 0)\n",
    "        \n",
    "        # Denormalize the image\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        img = std * img + mean\n",
    "        img = np.clip(img, 0, 1)\n",
    "        img = np.uint8(255 * img)\n",
    "    elif img.dtype != np.uint8:\n",
    "        img = np.uint8(255 * img)\n",
    "    \n",
    "    # Superimpose the heatmap on original image\n",
    "    superimposed_img = cv2.addWeighted(img, 1.0 - alpha, heatmap, alpha, 0)\n",
    "    \n",
    "    return superimposed_img\n",
    "\n",
    "def identify_affected_areas(heatmap, threshold=0.7):\n",
    "    \"\"\"Identify affected brain areas based on the heatmap\"\"\"\n",
    "    # Binarize the heatmap using the threshold\n",
    "    binary_heatmap = heatmap > threshold\n",
    "    \n",
    "    # Calculate the centroid of the affected area\n",
    "    y_indices, x_indices = np.where(binary_heatmap)\n",
    "    if len(y_indices) == 0 or len(x_indices) == 0:\n",
    "        return [\"No specific affected areas detected\"]\n",
    "    \n",
    "    centroid_y = np.mean(y_indices)\n",
    "    centroid_x = np.mean(x_indices)\n",
    "    \n",
    "    # Brain region mapping based on image quadrants\n",
    "    h, w = heatmap.shape\n",
    "    regions = []\n",
    "    \n",
    "    # Left vs Right\n",
    "    if centroid_x < w/2:\n",
    "        regions.append(\"Left hemisphere\")\n",
    "    else:\n",
    "        regions.append(\"Right hemisphere\")\n",
    "    \n",
    "    # Anterior vs Posterior\n",
    "    if centroid_y < h/2:\n",
    "        regions.append(\"Anterior region\")\n",
    "    else:\n",
    "        regions.append(\"Posterior region\")\n",
    "    \n",
    "    # Check specific quadrants for more detailed localization\n",
    "    if centroid_x < w/3:\n",
    "        if centroid_y < h/3:\n",
    "            regions.append(\"Possibly frontal lobe\")\n",
    "        elif centroid_y > 2*h/3:\n",
    "            regions.append(\"Possibly occipital lobe\")\n",
    "        else:\n",
    "            regions.append(\"Possibly temporal lobe\")\n",
    "    elif centroid_x > 2*w/3:\n",
    "        if centroid_y < h/3:\n",
    "            regions.append(\"Possibly frontal lobe\")\n",
    "        elif centroid_y > 2*h/3:\n",
    "            regions.append(\"Possibly occipital lobe\")\n",
    "        else:\n",
    "            regions.append(\"Possibly temporal lobe\")\n",
    "    else:\n",
    "        if centroid_y < h/2:\n",
    "            regions.append(\"Possibly parietal lobe\")\n",
    "        else:\n",
    "            regions.append(\"Possibly cerebellum or brain stem\")\n",
    "    \n",
    "    # Add a disclaimer\n",
    "    regions.append(\"Note: This is a preliminary estimate and should be confirmed by a medical professional\")\n",
    "    \n",
    "    return regions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ff59f4",
   "metadata": {},
   "source": [
    "## Making Predictions with Ensemble Model\n",
    "\n",
    "Let's implement a function to make predictions with our ensemble model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97db5a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models(models_dir='models_pytorch'):\n",
    "    \"\"\"Load all trained models\"\"\"\n",
    "    models = {}\n",
    "    model_names = ['densenet121', 'resnet50', 'efficientnet']\n",
    "    \n",
    "    for model_name in model_names:\n",
    "        model_path = os.path.join(models_dir, f\"stroke_{model_name}.pkl\")\n",
    "        if os.path.exists(model_path):\n",
    "            logger.info(f\"Loading {model_name} model from {model_path}\")\n",
    "            try:\n",
    "                with open(model_path, 'rb') as f:\n",
    "                    models[model_name] = pickle.load(f).to(device)\n",
    "                models[model_name].eval()\n",
    "                logger.info(f\"Successfully loaded {model_name} model\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error loading {model_name} model: {str(e)}\")\n",
    "    \n",
    "    if not models:\n",
    "        logger.warning(\"No models were loaded. Make sure the model files exist.\")\n",
    "    \n",
    "    return models\n",
    "\n",
    "def predict_stroke(image_path, models=None):\n",
    "    \"\"\"Predict stroke from a brain CT scan image using ensemble of models\"\"\"\n",
    "    # Load models if not provided\n",
    "    if models is None:\n",
    "        models = load_models()\n",
    "    \n",
    "    if not models:\n",
    "        raise ValueError(\"No models available for prediction\")\n",
    "    \n",
    "    # Load image\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    \n",
    "    # Preprocess image\n",
    "    transform = get_transforms(is_training=False)\n",
    "    img_tensor = transform(img).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Keep a copy of the resized image for visualization\n",
    "    img_resized = img.resize((256, 256))\n",
    "    img_array = np.array(img_resized)\n",
    "    \n",
    "    # Normalize for gradcam\n",
    "    img_normalized = transform(img).to(device)\n",
    "    \n",
    "    # Make predictions with each model\n",
    "    predictions = {}\n",
    "    for model_name, model in models.items():\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(img_tensor)\n",
    "            probs = F.softmax(outputs, dim=1)[0].cpu().numpy()\n",
    "            \n",
    "            predictions[model_name] = {\n",
    "                'normal_prob': float(probs[0]),\n",
    "                'stroke_prob': float(probs[1])\n",
    "            }\n",
    "    \n",
    "    # Calculate ensemble prediction (average of all models)\n",
    "    ensemble_normal_prob = np.mean([pred['normal_prob'] for pred in predictions.values()])\n",
    "    ensemble_stroke_prob = np.mean([pred['stroke_prob'] for pred in predictions.values()])\n",
    "    \n",
    "    # Determine the predicted class\n",
    "    predicted_class = 'Stroke' if ensemble_stroke_prob > 0.5 else 'Normal'\n",
    "    \n",
    "    # Generate heatmap for the most confident model\n",
    "    most_confident_model_name = max(\n",
    "        predictions.keys(), \n",
    "        key=lambda k: predictions[k]['stroke_prob'] if predicted_class == 'Stroke' else predictions[k]['normal_prob']\n",
    "    )\n",
    "    most_confident_model = models[most_confident_model_name]\n",
    "    \n",
    "    # Create GradCAM for visualization\n",
    "    heatmap = generate_gradcam(img_normalized, most_confident_model)\n",
    "    \n",
    "    # Create superimposed image\n",
    "    superimposed_img = superimpose_heatmap(img_array, heatmap)\n",
    "    \n",
    "    # Identify potentially affected areas\n",
    "    affected_areas = identify_affected_areas(heatmap)\n",
    "    \n",
    "    result = {\n",
    "        'predicted_class': predicted_class,\n",
    "        'confidence': float(ensemble_stroke_prob if predicted_class == 'Stroke' else ensemble_normal_prob),\n",
    "        'model_predictions': predictions,\n",
    "        'heatmap_image': superimposed_img,\n",
    "        'heatmap': heatmap,  # Raw heatmap for affected area identification\n",
    "        'affected_areas': affected_areas\n",
    "    }\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bfb3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test prediction on sample images\n",
    "def display_prediction(image_path, models=None):\n",
    "    \"\"\"Display prediction results for a single image\"\"\"\n",
    "    try:\n",
    "        result = predict_stroke(image_path, models)\n",
    "        \n",
    "        # Print prediction details\n",
    "        print(f\"Predicted class: {result['predicted_class']}\")\n",
    "        print(f\"Confidence: {result['confidence']:.4f}\")\n",
    "        \n",
    "        for model_name, pred in result['model_predictions'].items():\n",
    "            print(f\"{model_name}: Normal={pred['normal_prob']:.4f}, Stroke={pred['stroke_prob']:.4f}\")\n",
    "        \n",
    "        # Print potentially affected areas\n",
    "        print(\"\\nPotentially affected brain areas:\")\n",
    "        for area in result['affected_areas']:\n",
    "            print(f\"- {area}\")\n",
    "        \n",
    "        # Visualize the result\n",
    "        plt.figure(figsize=(18, 6))\n",
    "        \n",
    "        # Original image\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(plt.imread(image_path))\n",
    "        plt.title(\"Original Image\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # GradCAM heatmap\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(result['heatmap'], cmap='jet')\n",
    "        plt.title(\"GradCAM Heatmap\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Superimposed image\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(result['heatmap_image'])\n",
    "        plt.title(f\"Prediction: {result['predicted_class']} (Confidence: {result['confidence']:.4f})\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return result\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error predicting on {image_path}: {str(e)}\")\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Load all models\n",
    "loaded_models = load_models()\n",
    "\n",
    "# Test on sample images\n",
    "sample_paths = [\n",
    "    os.path.join(test_dir, 'Normal', '50 (10).jpg'),\n",
    "    os.path.join(test_dir, 'Stroke', '70 (33).jpg')\n",
    "]\n",
    "\n",
    "for sample_path in sample_paths:\n",
    "    if os.path.exists(sample_path):\n",
    "        print(f\"\\nPredicting on {sample_path}...\")\n",
    "        display_prediction(sample_path, loaded_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b37287",
   "metadata": {},
   "source": [
    "## Comprehensive Training Set Analysis with GradCAM\n",
    "\n",
    "Now let's analyze all training images with GradCAM visualization and generate comprehensive statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e2ebc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradcam_analysis.py\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import seaborn as sns\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def analyze_training_images(base_dir='Brain_Stroke_CT-SCAN_image', \n",
    "                           models_dir='models_pytorch',\n",
    "                           output_dir='gradcam_analysis',\n",
    "                           batch_size=16,\n",
    "                           sample_limit=None,\n",
    "                           save_all_images=True):\n",
    "    \"\"\"\n",
    "    Analyze all training images with GradCAM visualization and provide comprehensive statistics\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    base_dir : str\n",
    "        Base directory containing the dataset\n",
    "    models_dir : str\n",
    "        Directory containing the trained models\n",
    "    output_dir : str\n",
    "        Directory to save the analysis results\n",
    "    batch_size : int\n",
    "        Batch size for processing images\n",
    "    sample_limit : int or None\n",
    "        If set, limits the number of images processed per class\n",
    "    save_all_images : bool\n",
    "        Whether to save GradCAM visualizations for all images\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Comprehensive analysis results\n",
    "    \"\"\"\n",
    "    print(\"Starting comprehensive GradCAM analysis of training images...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create output directory\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Define dataset directories\n",
    "    train_dir = os.path.join(base_dir, 'Train')\n",
    "    \n",
    "    # Load all models\n",
    "    models = load_models(models_dir)\n",
    "    if not models:\n",
    "        raise ValueError(\"No models could be loaded. Please ensure models exist in the specified directory.\")\n",
    "    \n",
    "    # Initialize containers for analysis\n",
    "    classes = sorted([d for d in os.listdir(train_dir) if os.path.isdir(os.path.join(train_dir, d))])\n",
    "    all_predictions = {class_name: [] for class_name in classes}\n",
    "    all_labels = {class_name: [] for class_name in classes}\n",
    "    all_confidences = {class_name: [] for class_name in classes}\n",
    "    model_agreements = {class_name: [] for class_name in classes}\n",
    "    affected_areas_stats = {class_name: {} for class_name in classes}\n",
    "    \n",
    "    # Process images by class\n",
    "    for class_idx, class_name in enumerate(classes):\n",
    "        class_dir = os.path.join(train_dir, class_name)\n",
    "        image_files = [f for f in os.listdir(class_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        \n",
    "        if sample_limit:\n",
    "            if len(image_files) > sample_limit:\n",
    "                image_files = np.random.choice(image_files, sample_limit, replace=False)\n",
    "        \n",
    "        print(f\"\\nProcessing {len(image_files)} images from class: {class_name}\")\n",
    "        \n",
    "        # Create class output directory for images if saving all\n",
    "        if save_all_images:\n",
    "            class_output_dir = os.path.join(output_dir, class_name)\n",
    "            os.makedirs(class_output_dir, exist_ok=True)\n",
    "        \n",
    "        # Process all images\n",
    "        for img_idx, img_file in enumerate(tqdm(image_files, desc=f\"Class: {class_name}\")):\n",
    "            img_path = os.path.join(class_dir, img_file)\n",
    "            \n",
    "            try:\n",
    "                # Get prediction and GradCAM\n",
    "                result = predict_stroke(img_path, models)\n",
    "                \n",
    "                # Store prediction results\n",
    "                all_predictions[class_name].append(result['predicted_class'])\n",
    "                all_labels[class_name].append(class_name)  # True label is the class directory name\n",
    "                all_confidences[class_name].append(result['confidence'])\n",
    "                \n",
    "                # Calculate model agreement\n",
    "                predictions = [1 if pred['stroke_prob'] > 0.5 else 0 \n",
    "                              for pred in result['model_predictions'].values()]\n",
    "                agreement = 1.0 if len(set(predictions)) == 1 else sum(predictions) / len(predictions)\n",
    "                model_agreements[class_name].append(agreement)\n",
    "                \n",
    "                # Store affected areas\n",
    "                if result['predicted_class'] == 'Stroke':\n",
    "                    for area in result['affected_areas']:\n",
    "                        if area not in affected_areas_stats[class_name]:\n",
    "                            affected_areas_stats[class_name][area] = 0\n",
    "                        affected_areas_stats[class_name][area] += 1\n",
    "                \n",
    "                # Save GradCAM visualization\n",
    "                if save_all_images:\n",
    "                    # Create figure with original, heatmap and overlay\n",
    "                    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "                    \n",
    "                    # Original image\n",
    "                    img = Image.open(img_path).convert('RGB')\n",
    "                    img_resized = img.resize((256, 256))\n",
    "                    axes[0].imshow(img_resized)\n",
    "                    axes[0].set_title(\"Original Image\")\n",
    "                    axes[0].axis('off')\n",
    "                    \n",
    "                    # GradCAM heatmap\n",
    "                    axes[1].imshow(result['heatmap'], cmap='jet')\n",
    "                    axes[1].set_title(\"GradCAM Heatmap\")\n",
    "                    axes[1].axis('off')\n",
    "                    \n",
    "                    # Superimposed image\n",
    "                    axes[2].imshow(result['heatmap_image'])\n",
    "                    pred_class = result['predicted_class']\n",
    "                    confidence = result['confidence']\n",
    "                    correct = pred_class == class_name\n",
    "                    color = 'green' if correct else 'red'\n",
    "                    title = f\"Pred: {pred_class} ({confidence:.2f})\\nCorrect: {correct}\"\n",
    "                    axes[2].set_title(title, color=color)\n",
    "                    axes[2].axis('off')\n",
    "                    \n",
    "                    plt.tight_layout()\n",
    "                    \n",
    "                    # Save figure\n",
    "                    output_filename = os.path.join(class_output_dir, f\"{os.path.splitext(img_file)[0]}_gradcam.png\")\n",
    "                    plt.savefig(output_filename, dpi=150, bbox_inches='tight')\n",
    "                    plt.close(fig)\n",
    "                \n",
    "                # Optional: Save a sample of selected images regardless of save_all_images setting\n",
    "                if img_idx < 5:  # Save first 5 images as samples\n",
    "                    sample_dir = os.path.join(output_dir, 'samples')\n",
    "                    os.makedirs(sample_dir, exist_ok=True)\n",
    "                    \n",
    "                    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "                    \n",
    "                    # Original image\n",
    "                    img = Image.open(img_path).convert('RGB')\n",
    "                    img_resized = img.resize((256, 256))\n",
    "                    axes[0].imshow(img_resized)\n",
    "                    axes[0].set_title(\"Original Image\")\n",
    "                    axes[0].axis('off')\n",
    "                    \n",
    "                    # GradCAM heatmap\n",
    "                    axes[1].imshow(result['heatmap'], cmap='jet')\n",
    "                    axes[1].set_title(\"GradCAM Heatmap\")\n",
    "                    axes[1].axis('off')\n",
    "                    \n",
    "                    # Superimposed image\n",
    "                    axes[2].imshow(result['heatmap_image'])\n",
    "                    pred_class = result['predicted_class']\n",
    "                    confidence = result['confidence']\n",
    "                    correct = pred_class == class_name\n",
    "                    color = 'green' if correct else 'red'\n",
    "                    title = f\"Pred: {pred_class} ({confidence:.2f})\\nCorrect: {correct}\"\n",
    "                    axes[2].set_title(title, color=color)\n",
    "                    axes[2].axis('off')\n",
    "                    \n",
    "                    plt.tight_layout()\n",
    "                    \n",
    "                    # Save figure\n",
    "                    output_filename = os.path.join(sample_dir, f\"{class_name}_{img_idx}_gradcam.png\")\n",
    "                    plt.savefig(output_filename, dpi=150, bbox_inches='tight')\n",
    "                    plt.close(fig)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {img_path}: {str(e)}\")\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    all_predictions_flat = []\n",
    "    all_labels_flat = []\n",
    "    for class_name in classes:\n",
    "        all_predictions_flat.extend([1 if pred == 'Stroke' else 0 for pred in all_predictions[class_name]])\n",
    "        all_labels_flat.extend([1 if label == 'Stroke' else 0 for label in all_labels[class_name]])\n",
    "    \n",
    "    # Create confusion matrix\n",
    "    cm = confusion_matrix(all_labels_flat, all_predictions_flat)\n",
    "    \n",
    "    # Calculate per-class accuracy\n",
    "    class_accuracy = {}\n",
    "    for class_name in classes:\n",
    "        preds = all_predictions[class_name]\n",
    "        labels = all_labels[class_name]\n",
    "        correct = sum(1 for p, l in zip(preds, labels) if p == l)\n",
    "        class_accuracy[class_name] = correct / len(labels) if labels else 0\n",
    "    \n",
    "    # Create classification report\n",
    "    report = classification_report(all_labels_flat, all_predictions_flat, \n",
    "                                  target_names=classes, output_dict=True)\n",
    "    \n",
    "    # Visualize and save results\n",
    "    # 1. Confusion Matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "               xticklabels=classes, yticklabels=classes)\n",
    "    plt.title('Confusion Matrix - Training Set')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'confusion_matrix.png'), dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 2. Classification Report as Table\n",
    "    report_df = pd.DataFrame(report).transpose()\n",
    "    report_df.to_csv(os.path.join(output_dir, 'classification_report.csv'))\n",
    "    \n",
    "    # 3. Confidence Distribution\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i, class_name in enumerate(classes):\n",
    "        sns.histplot(all_confidences[class_name], bins=20, alpha=0.6, label=class_name)\n",
    "    plt.title('Prediction Confidence Distribution')\n",
    "    plt.xlabel('Confidence')\n",
    "    plt.ylabel('Count')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(output_dir, 'confidence_distribution.png'), dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 4. Model Agreement\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i, class_name in enumerate(classes):\n",
    "        sns.histplot(model_agreements[class_name], bins=10, alpha=0.6, label=class_name)\n",
    "    plt.title('Model Agreement Distribution')\n",
    "    plt.xlabel('Agreement Ratio (0=Disagreement, 1=Full Agreement)')\n",
    "    plt.ylabel('Count')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(output_dir, 'model_agreement.png'), dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 5. Affected Areas Distribution (for Stroke predictions)\n",
    "    for class_name in classes:\n",
    "        if affected_areas_stats[class_name]:\n",
    "            # Filter out the disclaimer note\n",
    "            disclaimer = \"Note: This is a preliminary estimate and should be confirmed by a medical professional\"\n",
    "            filtered_areas = {k: v for k, v in affected_areas_stats[class_name].items() if k != disclaimer}\n",
    "            \n",
    "            plt.figure(figsize=(12, 8))\n",
    "            area_names = list(filtered_areas.keys())\n",
    "            area_counts = list(filtered_areas.values())\n",
    "            \n",
    "            # Sort by frequency\n",
    "            sorted_indices = np.argsort(area_counts)[::-1]\n",
    "            sorted_names = [area_names[i] for i in sorted_indices]\n",
    "            sorted_counts = [area_counts[i] for i in sorted_indices]\n",
    "            \n",
    "            plt.barh(sorted_names, sorted_counts)\n",
    "            plt.title(f'Affected Brain Areas Distribution - {class_name}')\n",
    "            plt.xlabel('Count')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(output_dir, f'affected_areas_{class_name}.png'), dpi=150, bbox_inches='tight')\n",
    "            plt.close()\n",
    "    \n",
    "    # 6. Summary Statistics\n",
    "    summary = {\n",
    "        'Total Images': sum(len(all_predictions[c]) for c in classes),\n",
    "        'Class Distribution': {c: len(all_predictions[c]) for c in classes},\n",
    "        'Overall Accuracy': accuracy_score(all_labels_flat, all_predictions_flat),\n",
    "        'Class Accuracy': class_accuracy,\n",
    "        'Average Confidence': {c: np.mean(all_confidences[c]) for c in classes},\n",
    "        'Model Agreement': {c: np.mean(model_agreements[c]) for c in classes},\n",
    "        'Processing Time': time.time() - start_time\n",
    "    }\n",
    "    \n",
    "    # Save summary to file\n",
    "    with open(os.path.join(output_dir, 'summary_statistics.txt'), 'w') as f:\n",
    "        f.write(\"BRAIN STROKE CT SCAN ANALYSIS - TRAINING SET SUMMARY\\n\")\n",
    "        f.write(\"=\"*50 + \"\\n\\n\")\n",
    "        \n",
    "        f.write(f\"Total Images Processed: {summary['Total Images']}\\n\")\n",
    "        f.write(\"Class Distribution:\\n\")\n",
    "        for c, count in summary['Class Distribution'].items():\n",
    "            f.write(f\"  - {c}: {count} images\\n\")\n",
    "        \n",
    "        f.write(f\"\\nOverall Accuracy: {summary['Overall Accuracy']:.4f}\\n\")\n",
    "        f.write(\"Class-wise Accuracy:\\n\")\n",
    "        for c, acc in summary['Class Accuracy'].items():\n",
    "            f.write(f\"  - {c}: {acc:.4f}\\n\")\n",
    "        \n",
    "        f.write(\"\\nAverage Prediction Confidence:\\n\")\n",
    "        for c, conf in summary['Average Confidence'].items():\n",
    "            f.write(f\"  - {c}: {conf:.4f}\\n\")\n",
    "        \n",
    "        f.write(\"\\nAverage Model Agreement (1=full agreement):\\n\")\n",
    "        for c, agree in summary['Model Agreement'].items():\n",
    "            f.write(f\"  - {c}: {agree:.4f}\\n\")\n",
    "            \n",
    "        f.write(f\"\\nProcessing Time: {summary['Processing Time']:.2f} seconds\\n\")\n",
    "    \n",
    "    print(f\"\\nAnalysis completed in {summary['Processing Time']:.2f} seconds.\")\n",
    "    print(f\"Results saved to {output_dir}\")\n",
    "    \n",
    "    return summary\n",
    "\n",
    "def analyze_training_images_parallel(base_dir='Brain_Stroke_CT-SCAN_image', \n",
    "                                    models_dir='models_pytorch',\n",
    "                                    output_dir='gradcam_analysis',\n",
    "                                    num_workers=4,\n",
    "                                    sample_limit=None):\n",
    "    \"\"\"\n",
    "    Analyze training images in parallel using thread pool\n",
    "    \"\"\"\n",
    "    print(\"Starting parallel GradCAM analysis of training images...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create output directory\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Define dataset directories\n",
    "    train_dir = os.path.join(base_dir, 'Train')\n",
    "    \n",
    "    # Load all models\n",
    "    models = load_models(models_dir)\n",
    "    if not models:\n",
    "        raise ValueError(\"No models could be loaded. Please ensure models exist in the specified directory.\")\n",
    "    \n",
    "    # Get classes and prepare image paths\n",
    "    classes = sorted([d for d in os.listdir(train_dir) if os.path.isdir(os.path.join(train_dir, d))])\n",
    "    \n",
    "    image_paths = []\n",
    "    true_labels = []\n",
    "    \n",
    "    for class_name in classes:\n",
    "        class_dir = os.path.join(train_dir, class_name)\n",
    "        image_files = [f for f in os.listdir(class_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        \n",
    "        if sample_limit:\n",
    "            if len(image_files) > sample_limit:\n",
    "                image_files = np.random.choice(image_files, sample_limit, replace=False)\n",
    "        \n",
    "        for img_file in image_files:\n",
    "            img_path = os.path.join(class_dir, img_file)\n",
    "            image_paths.append(img_path)\n",
    "            true_labels.append(class_name)\n",
    "    \n",
    "    print(f\"Processing {len(image_paths)} total images from {len(classes)} classes\")\n",
    "    \n",
    "    # Define processing function\n",
    "    def process_image(args):\n",
    "        img_path, true_label = args\n",
    "        try:\n",
    "            result = predict_stroke(img_path, models)\n",
    "            result['true_label'] = true_label\n",
    "            result['path'] = img_path\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_path}: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    # Process images in parallel\n",
    "    results = []\n",
    "    with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "        for result in tqdm(executor.map(process_image, zip(image_paths, true_labels)), \n",
    "                          total=len(image_paths), desc=\"Processing images\"):\n",
    "            if result:\n",
    "                results.append(result)\n",
    "    \n",
    "    # Organize results\n",
    "    all_predictions = {class_name: [] for class_name in classes}\n",
    "    all_labels = {class_name: [] for class_name in classes}\n",
    "    all_confidences = {class_name: [] for class_name in classes}\n",
    "    model_agreements = {class_name: [] for class_name in classes}\n",
    "    affected_areas_stats = {class_name: {} for class_name in classes}\n",
    "    \n",
    "    for result in results:\n",
    "        class_name = result['true_label']\n",
    "        all_predictions[class_name].append(result['predicted_class'])\n",
    "        all_labels[class_name].append(class_name)\n",
    "        all_confidences[class_name].append(result['confidence'])\n",
    "        \n",
    "        # Calculate model agreement\n",
    "        predictions = [1 if pred['stroke_prob'] > 0.5 else 0 \n",
    "                      for pred in result['model_predictions'].values()]\n",
    "        agreement = 1.0 if len(set(predictions)) == 1 else sum(predictions) / len(predictions)\n",
    "        model_agreements[class_name].append(agreement)\n",
    "        \n",
    "        # Store affected areas\n",
    "        if result['predicted_class'] == 'Stroke':\n",
    "            for area in result['affected_areas']:\n",
    "                if area not in affected_areas_stats[class_name]:\n",
    "                    affected_areas_stats[class_name][area] = 0\n",
    "                affected_areas_stats[class_name][area] += 1\n",
    "    \n",
    "    # Save sample images\n",
    "    sample_dir = os.path.join(output_dir, 'samples')\n",
    "    os.makedirs(sample_dir, exist_ok=True)\n",
    "    \n",
    "    for class_name in classes:\n",
    "        class_results = [r for r in results if r['true_label'] == class_name]\n",
    "        if not class_results:\n",
    "            continue\n",
    "            \n",
    "        # Select a few samples\n",
    "        samples = np.random.choice(class_results, min(5, len(class_results)), replace=False)\n",
    "        \n",
    "        for i, result in enumerate(samples):\n",
    "            img_path = result['path']\n",
    "            \n",
    "            fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "            \n",
    "            # Original image\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            img_resized = img.resize((256, 256))\n",
    "            axes[0].imshow(img_resized)\n",
    "            axes[0].set_title(\"Original Image\")\n",
    "            axes[0].axis('off')\n",
    "            \n",
    "            # GradCAM heatmap\n",
    "            axes[1].imshow(result['heatmap'], cmap='jet')\n",
    "            axes[1].set_title(\"GradCAM Heatmap\")\n",
    "            axes[1].axis('off')\n",
    "            \n",
    "            # Superimposed image\n",
    "            axes[2].imshow(result['heatmap_image'])\n",
    "            pred_class = result['predicted_class']\n",
    "            confidence = result['confidence']\n",
    "            correct = pred_class == class_name\n",
    "            color = 'green' if correct else 'red'\n",
    "            title = f\"Pred: {pred_class} ({confidence:.2f})\\nCorrect: {correct}\"\n",
    "            axes[2].set_title(title, color=color)\n",
    "            axes[2].axis('off')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # Save figure\n",
    "            output_filename = os.path.join(sample_dir, f\"{class_name}_{i}_gradcam.png\")\n",
    "            plt.savefig(output_filename, dpi=150, bbox_inches='tight')\n",
    "            plt.close(fig)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    all_predictions_flat = []\n",
    "    all_labels_flat = []\n",
    "    for class_name in classes:\n",
    "        all_predictions_flat.extend([1 if pred == 'Stroke' else 0 for pred in all_predictions[class_name]])\n",
    "        all_labels_flat.extend([1 if label == 'Stroke' else 0 for label in all_labels[class_name]])\n",
    "    \n",
    "    # Create confusion matrix\n",
    "    cm = confusion_matrix(all_labels_flat, all_predictions_flat)\n",
    "    \n",
    "    # Calculate per-class accuracy\n",
    "    class_accuracy = {}\n",
    "    for class_name in classes:\n",
    "        preds = all_predictions[class_name]\n",
    "        labels = all_labels[class_name]\n",
    "        correct = sum(1 for p, l in zip(preds, labels) if p == l)\n",
    "        class_accuracy[class_name] = correct / len(labels) if labels else 0\n",
    "    \n",
    "    # Create classification report\n",
    "    report = classification_report(all_labels_flat, all_predictions_flat, \n",
    "                                 target_names=classes, output_dict=True)\n",
    "    \n",
    "    # Create visualizations (same as in sequential version)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "              xticklabels=classes, yticklabels=classes)\n",
    "    plt.title('Confusion Matrix - Training Set')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'confusion_matrix.png'), dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Classification Report as Table\n",
    "    report_df = pd.DataFrame(report).transpose()\n",
    "    report_df.to_csv(os.path.join(output_dir, 'classification_report.csv'))\n",
    "    \n",
    "    # Confidence Distribution\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i, class_name in enumerate(classes):\n",
    "        sns.histplot(all_confidences[class_name], bins=20, alpha=0.6, label=class_name)\n",
    "    plt.title('Prediction Confidence Distribution')\n",
    "    plt.xlabel('Confidence')\n",
    "    plt.ylabel('Count')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(output_dir, 'confidence_distribution.png'), dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Model Agreement\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i, class_name in enumerate(classes):\n",
    "        sns.histplot(model_agreements[class_name], bins=10, alpha=0.6, label=class_name)\n",
    "    plt.title('Model Agreement Distribution')\n",
    "    plt.xlabel('Agreement Ratio (0=Disagreement, 1=Full Agreement)')\n",
    "    plt.ylabel('Count')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(output_dir, 'model_agreement.png'), dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Summary Statistics\n",
    "    summary = {\n",
    "        'Total Images': sum(len(all_predictions[c]) for c in classes),\n",
    "        'Class Distribution': {c: len(all_predictions[c]) for c in classes},\n",
    "        'Overall Accuracy': accuracy_score(all_labels_flat, all_predictions_flat),\n",
    "        'Class Accuracy': class_accuracy,\n",
    "        'Average Confidence': {c: np.mean(all_confidences[c]) for c in classes},\n",
    "        'Model Agreement': {c: np.mean(model_agreements[c]) for c in classes},\n",
    "        'Processing Time': time.time() - start_time\n",
    "    }\n",
    "    \n",
    "    # Save summary to file\n",
    "    with open(os.path.join(output_dir, 'summary_statistics.txt'), 'w') as f:\n",
    "        f.write(\"BRAIN STROKE CT SCAN ANALYSIS - TRAINING SET SUMMARY\\n\")\n",
    "        f.write(\"=\"*50 + \"\\n\\n\")\n",
    "        \n",
    "        f.write(f\"Total Images Processed: {summary['Total Images']}\\n\")\n",
    "        f.write(\"Class Distribution:\\n\")\n",
    "        for c, count in summary['Class Distribution'].items():\n",
    "            f.write(f\"  - {c}: {count} images\\n\")\n",
    "        \n",
    "        f.write(f\"\\nOverall Accuracy: {summary['Overall Accuracy']:.4f}\\n\")\n",
    "        f.write(\"Class-wise Accuracy:\\n\")\n",
    "        for c, acc in summary['Class Accuracy'].items():\n",
    "            f.write(f\"  - {c}: {acc:.4f}\\n\")\n",
    "        \n",
    "        f.write(\"\\nAverage Prediction Confidence:\\n\")\n",
    "        for c, conf in summary['Average Confidence'].items():\n",
    "            f.write(f\"  - {c}: {conf:.4f}\\n\")\n",
    "        \n",
    "        f.write(\"\\nAverage Model Agreement (1=full agreement):\\n\")\n",
    "        for c, agree in summary['Model Agreement'].items():\n",
    "            f.write(f\"  - {c}: {agree:.4f}\\n\")\n",
    "            \n",
    "        f.write(f\"\\nProcessing Time: {summary['Processing Time']:.2f} seconds\\n\")\n",
    "    \n",
    "    print(f\"\\nParallel analysis completed in {summary['Processing Time']:.2f} seconds.\")\n",
    "    print(f\"Results saved to {output_dir}\")\n",
    "    \n",
    "    return summary\n",
    "\n",
    "def generate_advanced_visualizations(results_dir='gradcam_analysis', output_dir=None):\n",
    "    \"\"\"\n",
    "    Generate advanced visualizations based on GradCAM analysis results\n",
    "    \"\"\"\n",
    "    if output_dir is None:\n",
    "        output_dir = os.path.join(results_dir, 'advanced_visualizations')\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Load results\n",
    "    try:\n",
    "        # Load classification report\n",
    "        report_df = pd.read_csv(os.path.join(results_dir, 'classification_report.csv'))\n",
    "        \n",
    "        # Create radar chart for model performance\n",
    "        metrics = ['precision', 'recall', 'f1-score']\n",
    "        classes = [c for c in report_df.iloc[:,0] if c in ['Normal', 'Stroke']]\n",
    "        \n",
    "        values = []\n",
    "        for c in classes:\n",
    "            class_metrics = []\n",
    "            for metric in metrics:\n",
    "                try:\n",
    "                    val = report_df.loc[report_df.iloc[:,0] == c, metric].values[0]\n",
    "                    class_metrics.append(float(val))\n",
    "                except:\n",
    "                    class_metrics.append(0)\n",
    "            values.append(class_metrics)\n",
    "        \n",
    "        # Create radar chart\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        angles = np.linspace(0, 2*np.pi, len(metrics), endpoint=False).tolist()\n",
    "        angles += angles[:1]  # Close the loop\n",
    "        \n",
    "        ax = plt.subplot(111, polar=True)\n",
    "        \n",
    "        for i, class_name in enumerate(classes):\n",
    "            vals = values[i] + values[i][:1]  # Close the loop\n",
    "            ax.plot(angles, vals, linewidth=2, label=class_name)\n",
    "            ax.fill(angles, vals, alpha=0.25)\n",
    "        \n",
    "        ax.set_thetagrids(np.degrees(angles[:-1]), metrics)\n",
    "        ax.set_ylim(0, 1)\n",
    "        plt.legend(loc='upper right', bbox_to_anchor=(0.1, 0.1))\n",
    "        plt.title('Model Performance Metrics')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, 'radar_chart.png'), dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating advanced visualizations: {str(e)}\")\n",
    "\n",
    "def run_complete_analysis(base_dir='Brain_Stroke_CT-SCAN_image', \n",
    "                         models_dir='models_pytorch',\n",
    "                         output_dir='gradcam_analysis',\n",
    "                         parallel=True,\n",
    "                         num_workers=4,\n",
    "                         sample_limit=None):\n",
    "    \"\"\"\n",
    "    Run complete analysis pipeline\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    base_dir : str\n",
    "        Base directory containing the dataset\n",
    "    models_dir : str\n",
    "        Directory containing the trained models\n",
    "    output_dir : str\n",
    "        Directory to save the analysis results\n",
    "    parallel : bool\n",
    "        Whether to use parallel processing\n",
    "    num_workers : int\n",
    "        Number of worker threads for parallel processing\n",
    "    sample_limit : int or None\n",
    "        If set, limits the number of images processed per class\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Analysis summary statistics\n",
    "    \"\"\"\n",
    "    if parallel:\n",
    "        summary = analyze_training_images_parallel(\n",
    "            base_dir=base_dir,\n",
    "            models_dir=models_dir,\n",
    "            output_dir=output_dir,\n",
    "            num_workers=num_workers,\n",
    "            sample_limit=sample_limit\n",
    "        )\n",
    "    else:\n",
    "        summary = analyze_training_images(\n",
    "            base_dir=base_dir,\n",
    "            models_dir=models_dir,\n",
    "            output_dir=output_dir,\n",
    "            sample_limit=sample_limit\n",
    "        )\n",
    "    \n",
    "    # Generate advanced visualizations\n",
    "    generate_advanced_visualizations(results_dir=output_dir)\n",
    "    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21f2f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the comprehensive analysis\n",
    "analysis_results = run_complete_analysis(\n",
    "    base_dir='Brain_Stroke_CT-SCAN_image',  # Update if your dataset path is different\n",
    "    models_dir='models_pytorch',            # Update if your models path is different\n",
    "    output_dir='gradcam_analysis',\n",
    "    parallel=True,\n",
    "    num_workers=1,  # Adjust based on your CPU cores\n",
    "    sample_limit=None  # Takes x random images from both \"Normal\" and \"Stroke\" for processing; set \"sample_limit=None\" to process all images\n",
    ")\n",
    "\n",
    "# Display key results\n",
    "print(f\"Analysis complete! Overall accuracy: {analysis_results['Overall Accuracy']:.4f}\")\n",
    "print(\"\\nClass-wise accuracy:\")\n",
    "for class_name, acc in analysis_results['Class Accuracy'].items():\n",
    "    print(f\"  - {class_name}: {acc:.4f}\")\n",
    "\n",
    "print(\"\\nSee the 'gradcam_analysis' folder for comprehensive visualizations and reports.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361fc8fa",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This project demonstrates the use of deep learning for stroke detection from brain CT scans. We trained and evaluated three different CNN models (DenseNet121, ResNet50, EfficientNet B3) and combined them into an ensemble for improved performance.\n",
    "\n",
    "### Key Points:\n",
    "\n",
    "1. **Model Architecture**: We fine-tuned pre-trained models on our specific dataset, allowing us to benefit from transfer learning.\n",
    "   \n",
    "2. **Ensemble Approach**: By averaging predictions from multiple models, we achieved better performance than any single model.\n",
    "   \n",
    "3. **Model Interpretability**: Using Grad-CAM, we can visualize which regions of the brain influence the model's decision, providing a level of interpretability important for medical applications.\n",
    "   \n",
    "4. **Incremental Training**: The code allows for training one model at a time and saving the results, which is useful for limited computational resources.\n",
    "\n",
    "### Future Work:\n",
    "\n",
    "1. **Advanced Architectures**: Explore newer CNN architectures or transformer-based models for medical imaging.\n",
    "   \n",
    "2. **More Data**: Acquire and incorporate more training data to improve model robustness.\n",
    "   \n",
    "3. **Clinical Validation**: Work with medical professionals to validate model predictions on real-world cases.\n",
    "   \n",
    "4. **Stroke Type Classification**: Extend the model to classify different types of strokes (ischemic vs. hemorrhagic).\n",
    "   \n",
    "5. **Multi-modal Approach**: Combine CT scans with other data such as patient medical history for more comprehensive diagnosis.\n",
    "\n",
    "This project serves as a foundation for automated stroke detection systems that could assist radiologists in making faster and more accurate diagnoses, potentially improving patient outcomes through earlier intervention."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
