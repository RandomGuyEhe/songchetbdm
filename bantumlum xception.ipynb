{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3e21c8a",
   "metadata": {},
   "source": [
    "# Brain Stroke Detection from CT Scans using Deep Learning\n",
    "\n",
    "## Project Introduction\n",
    "\n",
    "This project aims to develop a deep learning-based system for the automatic detection of strokes in brain CT scans. Stroke is a medical emergency that requires immediate treatment to minimize brain damage and other complications. Early and accurate detection is crucial for improving patient outcomes.\n",
    "\n",
    "### Approach\n",
    "We will use an ensemble of three Convolutional Neural Networks (CNNs) pretrained on ImageNet:\n",
    "1. **DenseNet121** - Known for its dense connections that help with feature reuse and gradient flow\n",
    "2. **ResNet50** - Famous for its residual connections that solve the vanishing gradient problem\n",
    "3. **Xception** (or ResNet50 as PyTorch substitute) - A model that uses depthwise separable convolutions\n",
    "\n",
    "Each model will be fine-tuned on our brain CT scan dataset. We then use an ensemble approach by averaging the predictions from all three models to make the final classification decision.\n",
    "\n",
    "### Dataset\n",
    "The dataset contains brain CT scan images organized into two classes:\n",
    "- **Normal**: CT scans of normal brains\n",
    "- **Stroke**: CT scans showing evidence of stroke\n",
    "\n",
    "The dataset is already split into Train, Validation, and Test sets.\n",
    "\n",
    "### Visualization\n",
    "For the detected stroke cases, we will use Gradient-weighted Class Activation Mapping (Grad-CAM) to highlight the areas of the brain that influenced the model's decision, providing an interpretable visual explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c1a8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import logging\n",
    "import pickle\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"cnn_models_pytorch.log\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    logger.info(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    logger.info(\"Using CPU\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c12c89",
   "metadata": {},
   "source": [
    "## Dataset Definition\n",
    "\n",
    "First, we'll define our custom dataset class for brain CT scan images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c2a8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrainCTDataset(Dataset):\n",
    "    \"\"\"Custom Dataset for loading brain CT scan images\"\"\"\n",
    "    def __init__(self, directory, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            directory: Directory with all the images organized in class folders\n",
    "            transform: Optional transform to be applied on a sample\n",
    "        \"\"\"\n",
    "        self.directory = directory\n",
    "        self.transform = transform\n",
    "        self.classes = sorted([d for d in os.listdir(directory) if os.path.isdir(os.path.join(directory, d))])\n",
    "        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n",
    "        \n",
    "        self.samples = []\n",
    "        for class_name in self.classes:\n",
    "            class_dir = os.path.join(directory, class_name)\n",
    "            for img_name in os.listdir(class_dir):\n",
    "                if img_name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                    img_path = os.path.join(class_dir, img_name)\n",
    "                    self.samples.append((img_path, self.class_to_idx[class_name]))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        \n",
    "        try:\n",
    "            # Use PIL Image for compatibility with torchvision transforms\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            \n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            \n",
    "            return image, label\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading image {img_path}: {str(e)}\")\n",
    "            # Return a black image and the label on error\n",
    "            if self.transform:\n",
    "                default_img = torch.zeros((3, 256, 256))\n",
    "            else:\n",
    "                default_img = Image.new('RGB', (256, 256), (0, 0, 0))\n",
    "                if self.transform:\n",
    "                    default_img = self.transform(default_img)\n",
    "            return default_img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a43d81",
   "metadata": {},
   "source": [
    "## Data Visualization and Exploration\n",
    "\n",
    "Let's explore our dataset to understand its characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4d42a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataset directories\n",
    "base_dir = 'Brain_Stroke_CT-SCAN_image'\n",
    "train_dir = os.path.join(base_dir, 'Train')\n",
    "valid_dir = os.path.join(base_dir, 'Validation')\n",
    "test_dir = os.path.join(base_dir, 'Test')\n",
    "models_dir = 'models_pytorch'\n",
    "\n",
    "# Create models directory if it doesn't exist\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "# Function to count images by class\n",
    "def count_images(directory):\n",
    "    class_counts = {}\n",
    "    for class_name in os.listdir(directory):\n",
    "        class_dir = os.path.join(directory, class_name)\n",
    "        if os.path.isdir(class_dir):\n",
    "            count = len([f for f in os.listdir(class_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "            class_counts[class_name] = count\n",
    "    return class_counts\n",
    "\n",
    "# Count the number of images in each dataset split and class\n",
    "train_counts = count_images(train_dir)\n",
    "valid_counts = count_images(valid_dir)\n",
    "test_counts = count_images(test_dir)\n",
    "\n",
    "# Create a DataFrame for easier visualization\n",
    "counts_df = pd.DataFrame({\n",
    "    'Train': train_counts,\n",
    "    'Validation': valid_counts,\n",
    "    'Test': test_counts\n",
    "})\n",
    "\n",
    "print(\"Dataset Distribution:\")\n",
    "print(counts_df)\n",
    "\n",
    "# Visualize dataset distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "counts_df.plot(kind='bar', figsize=(10, 6))\n",
    "plt.title('Distribution of Classes Across Datasets')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.xlabel('Class')\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5512cfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some sample images from each class\n",
    "def display_samples(directory, num_samples=5):\n",
    "    \"\"\"Display sample images from each class\"\"\"\n",
    "    classes = sorted([d for d in os.listdir(directory) if os.path.isdir(os.path.join(directory, d))])\n",
    "    \n",
    "    plt.figure(figsize=(15, 8))\n",
    "    for i, class_name in enumerate(classes):\n",
    "        class_dir = os.path.join(directory, class_name)\n",
    "        images = [f for f in os.listdir(class_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        samples = random.sample(images, min(num_samples, len(images)))\n",
    "        \n",
    "        for j, img_name in enumerate(samples):\n",
    "            img_path = os.path.join(class_dir, img_name)\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            \n",
    "            plt.subplot(len(classes), num_samples, i * num_samples + j + 1)\n",
    "            plt.imshow(img)\n",
    "            plt.title(f\"{class_name}: {img_name}\")\n",
    "            plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Display sample images from training set\n",
    "print(\"Sample Training Images:\")\n",
    "display_samples(train_dir, num_samples=5)\n",
    "\n",
    "# Let's also check the image size of a random sample\n",
    "def check_image_stats(directory, num_samples=20):\n",
    "    \"\"\"Check image dimensions and aspect ratios\"\"\"\n",
    "    classes = sorted([d for d in os.listdir(directory) if os.path.isdir(os.path.join(directory, d))])\n",
    "    img_sizes = []\n",
    "    aspect_ratios = []\n",
    "    \n",
    "    for class_name in classes:\n",
    "        class_dir = os.path.join(directory, class_name)\n",
    "        images = [f for f in os.listdir(class_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        samples = random.sample(images, min(num_samples, len(images)))\n",
    "        \n",
    "        for img_name in samples:\n",
    "            img_path = os.path.join(class_dir, img_name)\n",
    "            img = Image.open(img_path)\n",
    "            width, height = img.size\n",
    "            img_sizes.append((width, height))\n",
    "            aspect_ratios.append(width / height)\n",
    "    \n",
    "    # Calculate statistics\n",
    "    widths = [w for w, h in img_sizes]\n",
    "    heights = [h for w, h in img_sizes]\n",
    "    \n",
    "    stats = {\n",
    "        'avg_width': np.mean(widths),\n",
    "        'avg_height': np.mean(heights),\n",
    "        'min_width': min(widths),\n",
    "        'min_height': min(heights),\n",
    "        'max_width': max(widths),\n",
    "        'max_height': max(heights),\n",
    "        'avg_aspect_ratio': np.mean(aspect_ratios)\n",
    "    }\n",
    "    \n",
    "    print(\"\\nImage Statistics:\")\n",
    "    for k, v in stats.items():\n",
    "        print(f\"{k}: {v:.2f}\")\n",
    "    \n",
    "    # Plot size distribution\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(widths, bins=10, alpha=0.7, label='Width')\n",
    "    plt.hist(heights, bins=10, alpha=0.7, label='Height')\n",
    "    plt.xlabel('Pixels')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Image Size Distribution')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(aspect_ratios, bins=10)\n",
    "    plt.xlabel('Aspect Ratio (Width/Height)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Aspect Ratio Distribution')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Check image statistics\n",
    "check_image_stats(train_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a77c89",
   "metadata": {},
   "source": [
    "## Model Definition and Training Utilities\n",
    "\n",
    "Now, let's define our model architecture and training utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34c59a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StrokeCTModel(nn.Module):\n",
    "    \"\"\"CNN model for stroke detection\"\"\"\n",
    "    def __init__(self, base_model_name, input_shape=(256, 256, 3), num_classes=2):\n",
    "        super(StrokeCTModel, self).__init__()\n",
    "        self.model_name = base_model_name.lower()\n",
    "        \n",
    "        # Initialize the base model\n",
    "        if self.model_name == 'densenet121':\n",
    "            self.base_model = models.densenet121(pretrained=True)\n",
    "            num_features = self.base_model.classifier.in_features\n",
    "            self.base_model.classifier = nn.Identity()\n",
    "            \n",
    "        elif self.model_name == 'resnet50':\n",
    "            self.base_model = models.resnet50(pretrained=True)\n",
    "            num_features = self.base_model.fc.in_features\n",
    "            self.base_model.fc = nn.Identity()\n",
    "            \n",
    "        elif self.model_name == 'xception':\n",
    "            # PyTorch doesn't have Xception built-in, use ResNet50 as replacement\n",
    "            logger.warning(\"PyTorch doesn't have Xception model. Using ResNet50 instead.\")\n",
    "            self.base_model = models.resnet50(pretrained=True)\n",
    "            num_features = self.base_model.fc.in_features\n",
    "            self.base_model.fc = nn.Identity()\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(f\"Unknown base model: {base_model_name}\")\n",
    "        \n",
    "        # Add custom layers\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(num_features, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1024, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        features = self.base_model(x)\n",
    "        return self.classifier(features)\n",
    "\n",
    "def create_model(base_model_name, input_shape=(256, 256, 3), num_classes=2):\n",
    "    \"\"\"\n",
    "    Create a CNN model using a pre-trained base model\n",
    "    \"\"\"\n",
    "    logger.info(f\"Creating {base_model_name} model...\")\n",
    "    model = StrokeCTModel(base_model_name, input_shape, num_classes)\n",
    "    model = model.to(device)\n",
    "    return model\n",
    "\n",
    "def get_transforms(is_training=False):\n",
    "    \"\"\"Get image transformations for training and testing\"\"\"\n",
    "    # Normalization values for ImageNet\n",
    "    normalize = transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "    \n",
    "    if is_training:\n",
    "        # Data augmentation for training\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(20),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "            transforms.RandomAffine(degrees=0, translate=(0.2, 0.2), scale=(0.8, 1.2)),\n",
    "            transforms.ToTensor(),\n",
    "            normalize\n",
    "        ])\n",
    "    else:\n",
    "        # Only resize and normalize for validation/testing\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.ToTensor(),\n",
    "            normalize\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a41fe22",
   "metadata": {},
   "source": [
    "## Training Function\n",
    "\n",
    "We'll define a function to train our models. Note that we'll train each model for 30 epochs instead of the original 100 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ddb37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_dir, valid_dir, model_name, input_shape=(256, 256), batch_size=32, epochs=30):\n",
    "    \"\"\"\n",
    "    Train a CNN model on the dataset and save it after training\n",
    "    \"\"\"\n",
    "    # Create datasets and data loaders\n",
    "    train_transform = get_transforms(is_training=True)\n",
    "    valid_transform = get_transforms(is_training=False)\n",
    "    \n",
    "    train_dataset = BrainCTDataset(train_dir, transform=train_transform)\n",
    "    valid_dataset = BrainCTDataset(valid_dir, transform=valid_transform)\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True, \n",
    "        num_workers=0, \n",
    "        pin_memory=False\n",
    "    )\n",
    "    \n",
    "    valid_loader = DataLoader(\n",
    "        valid_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False, \n",
    "        num_workers=0, \n",
    "        pin_memory=False\n",
    "    )\n",
    "    \n",
    "    logger.info(f\"Training samples: {len(train_dataset)}\")\n",
    "    logger.info(f\"Validation samples: {len(valid_dataset)}\")\n",
    "    \n",
    "    # Loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=5, verbose=True\n",
    "    )\n",
    "    \n",
    "    # Training history\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_loss': [],\n",
    "        'val_acc': []\n",
    "    }\n",
    "    \n",
    "    # Training loop\n",
    "    start_time = time.time()\n",
    "    best_val_acc = 0.0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_start = time.time()\n",
    "        \n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        train_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [Train]\")\n",
    "        for inputs, labels in train_bar:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Statistics\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Update progress bar\n",
    "            train_bar.set_postfix({\n",
    "                'loss': f\"{loss.item():.4f}\",\n",
    "                'acc': f\"{train_correct/train_total:.4f}\"\n",
    "            })\n",
    "        \n",
    "        train_loss = train_loss / len(train_loader.dataset)\n",
    "        train_acc = train_correct / train_total\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            val_bar = tqdm(valid_loader, desc=f\"Epoch {epoch+1}/{epochs} [Valid]\")\n",
    "            for inputs, labels in val_bar:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                # Statistics\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                \n",
    "                # Update progress bar\n",
    "                val_bar.set_postfix({\n",
    "                    'loss': f\"{loss.item():.4f}\",\n",
    "                    'acc': f\"{val_correct/val_total:.4f}\"\n",
    "                })\n",
    "        \n",
    "        val_loss = val_loss / len(valid_loader.dataset)\n",
    "        val_acc = val_correct / val_total\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # Update history\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        \n",
    "        # Calculate epoch time\n",
    "        epoch_time = time.time() - epoch_start\n",
    "        \n",
    "        # Print epoch statistics\n",
    "        logger.info(f\"Epoch {epoch+1}/{epochs} - \"\n",
    "                    f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
    "                    f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f} - \"\n",
    "                    f\"Time: {epoch_time:.2f}s\")\n",
    "        \n",
    "        # Save the model after each epoch (to be able to continue training later)\n",
    "        model_path = os.path.join(models_dir, f\"stroke_{model_name}_epoch_{epoch+1}.pkl\")\n",
    "        with open(model_path, 'wb') as f:\n",
    "            pickle.dump(model.cpu(), f)\n",
    "        # Move model back to device\n",
    "        model = model.to(device)\n",
    "        logger.info(f\"Model saved to {model_path}\")\n",
    "        \n",
    "        # Keep track of best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_model_path = os.path.join(models_dir, f\"stroke_{model_name}_best.pkl\")\n",
    "            with open(best_model_path, 'wb') as f:\n",
    "                pickle.dump(model.cpu(), f)\n",
    "            # Move model back to device\n",
    "            model = model.to(device)\n",
    "            logger.info(f\"Best model saved to {best_model_path} with validation accuracy: {best_val_acc:.4f}\")\n",
    "    \n",
    "    # Calculate total training time\n",
    "    total_time = time.time() - start_time\n",
    "    logger.info(f\"Training completed in {total_time:.2f}s\")\n",
    "    \n",
    "    # Final model save (for convenience)\n",
    "    final_model_path = os.path.join(models_dir, f\"stroke_{model_name}.pkl\")\n",
    "    with open(final_model_path, 'wb') as f:\n",
    "        pickle.dump(model.cpu(), f)\n",
    "    # Move model back to device for any further operations\n",
    "    model = model.to(device)\n",
    "    logger.info(f\"Final model saved to {final_model_path}\")\n",
    "    \n",
    "    # Plot and save training history\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history['train_acc'], label='Train')\n",
    "    plt.plot(history['val_acc'], label='Validation')\n",
    "    plt.title(f'{model_name.upper()} - Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history['train_loss'], label='Train')\n",
    "    plt.plot(history['val_loss'], label='Validation')\n",
    "    plt.title(f'{model_name.upper()} - Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(models_dir, f\"{model_name}_history.png\"))\n",
    "    plt.show()\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe8af27",
   "metadata": {},
   "source": [
    "## Training Models\n",
    "\n",
    "We'll train each model separately. You can run one model at a time and come back later to run the next model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7462a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_densenet121():\n",
    "    \"\"\"Train DenseNet121 model for stroke detection\"\"\"\n",
    "    logger.info(\"Training DENSENET121 model...\")\n",
    "    model = create_model('densenet121')\n",
    "    model, history = train_model(model, train_dir, valid_dir, 'densenet121', epochs=30)\n",
    "    return model, history\n",
    "\n",
    "# Uncomment to train DenseNet121\n",
    "# densenet_model, densenet_history = train_densenet121()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f4b93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_resnet50():\n",
    "    \"\"\"Train ResNet50 model for stroke detection\"\"\"\n",
    "    logger.info(\"Training RESNET50 model...\")\n",
    "    model = create_model('resnet50')\n",
    "    model, history = train_model(model, train_dir, valid_dir, 'resnet50', epochs=30)\n",
    "    return model, history\n",
    "\n",
    "# Uncomment to train ResNet50\n",
    "# resnet_model, resnet_history = train_resnet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b257e3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xception():\n",
    "    \"\"\"Train Xception model for stroke detection (actually ResNet50)\"\"\"\n",
    "    logger.info(\"Training XCEPTION model...\")\n",
    "    model = create_model('xception')\n",
    "    model, history = train_model(model, train_dir, valid_dir, 'xception', epochs=30)\n",
    "    return model, history\n",
    "\n",
    "# Uncomment to train Xception (actually ResNet50)\n",
    "# xception_model, xception_history = train_xception()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cff6a5",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "We'll implement functions to evaluate our models on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cb1fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_name):\n",
    "    \"\"\"Load a trained model from disk\"\"\"\n",
    "    model_path = os.path.join(models_dir, f\"stroke_{model_name}.pkl\")\n",
    "    if os.path.exists(model_path):\n",
    "        logger.info(f\"Loading {model_name} model from {model_path}\")\n",
    "        try:\n",
    "            with open(model_path, 'rb') as f:\n",
    "                model = pickle.load(f).to(device)\n",
    "            model.eval()\n",
    "            logger.info(f\"Successfully loaded {model_name} model\")\n",
    "            return model\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading {model_name} model: {str(e)}\")\n",
    "            return None\n",
    "    else:\n",
    "        logger.error(f\"Model file not found: {model_path}\")\n",
    "        return None\n",
    "    \n",
    "def evaluate_model(model, test_dir, input_shape=(256, 256), batch_size=32):\n",
    "    \"\"\"Evaluate a model on the test set\"\"\"\n",
    "    # Create dataset and data loader\n",
    "    test_transform = get_transforms(is_training=False)\n",
    "    test_dataset = BrainCTDataset(test_dir, transform=test_transform)\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False, \n",
    "        num_workers=0,\n",
    "        pin_memory=False\n",
    "    )\n",
    "    \n",
    "    logger.info(f\"Test samples: {len(test_dataset)}\")\n",
    "    \n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Initialize variables\n",
    "    test_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    \n",
    "    # Loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Evaluate the model\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Get predictions and probabilities\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            # Save predictions, probabilities, and labels\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            \n",
    "            # Update loss\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "    \n",
    "    # Calculate average loss\n",
    "    test_loss = test_loss / len(test_loader.dataset)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = np.mean(np.array(all_preds) == np.array(all_labels))\n",
    "    \n",
    "    # Create result dictionary\n",
    "    result = {\n",
    "        'loss': test_loss,\n",
    "        'accuracy': accuracy,\n",
    "        'predictions': all_preds,\n",
    "        'labels': all_labels,\n",
    "        'probabilities': all_probs\n",
    "    }\n",
    "    \n",
    "    # Calculate confusion matrix and classification report\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    class_names = test_dataset.classes\n",
    "    report = classification_report(all_labels, all_preds, target_names=class_names, output_dict=True)\n",
    "    \n",
    "    result['confusion_matrix'] = cm\n",
    "    result['classification_report'] = report\n",
    "    \n",
    "    return result\n",
    "\n",
    "def visualize_evaluation(result, model_name):\n",
    "    \"\"\"Visualize evaluation results\"\"\"\n",
    "    # Print evaluation metrics\n",
    "    print(f\"Model: {model_name.upper()}\")\n",
    "    \n",
    "    # Print loss if available (for individual models)\n",
    "    if 'loss' in result:\n",
    "        print(f\"Test Loss: {result['loss']:.4f}\")\n",
    "    else:\n",
    "        print(f\"Test Loss: N/A (not calculated for ensemble)\")\n",
    "    \n",
    "    print(f\"Test Accuracy: {result['accuracy']:.4f}\")\n",
    "    \n",
    "    # Print classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    report_df = pd.DataFrame(result['classification_report']).transpose()\n",
    "    print(report_df)\n",
    "    \n",
    "    # Visualize confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    cm = result['confusion_matrix']\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Normal', 'Stroke'], \n",
    "                yticklabels=['Normal', 'Stroke'])\n",
    "    plt.title(f'Confusion Matrix - {model_name.upper()}')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f723f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and evaluate each model\n",
    "models = ['densenet121', 'resnet50', 'xception']\n",
    "evaluation_results = {}\n",
    "\n",
    "for model_name in models:\n",
    "    model = load_model(model_name)\n",
    "    if model is not None:\n",
    "        result = evaluate_model(model, test_dir)\n",
    "        evaluation_results[model_name] = result\n",
    "        visualize_evaluation(result, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33da34b",
   "metadata": {},
   "source": [
    "## Ensemble Model Evaluation\n",
    "\n",
    "Let's evaluate the performance of the ensemble model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fc7dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ensemble(evaluation_results, test_dir):\n",
    "    \"\"\"Evaluate the ensemble of models\"\"\"\n",
    "    # Ensure we have results for all models\n",
    "    models = ['densenet121', 'resnet50', 'xception']\n",
    "    if not all(model in evaluation_results for model in models):\n",
    "        missing = [model for model in models if model not in evaluation_results]\n",
    "        logger.error(f\"Missing evaluation results for models: {missing}\")\n",
    "        return None\n",
    "    \n",
    "    # Get the test dataset labels\n",
    "    test_transform = get_transforms(is_training=False)\n",
    "    test_dataset = BrainCTDataset(test_dir, transform=test_transform)\n",
    "    \n",
    "    # Combine predictions from all models\n",
    "    ensemble_probs = np.zeros((len(evaluation_results['densenet121']['labels']), 2))\n",
    "    for model_name in models:\n",
    "        ensemble_probs += np.array(evaluation_results[model_name]['probabilities'])\n",
    "    \n",
    "    # Average the probabilities\n",
    "    ensemble_probs /= len(models)\n",
    "    \n",
    "    # Get the predicted classes\n",
    "    ensemble_preds = np.argmax(ensemble_probs, axis=1)\n",
    "    true_labels = evaluation_results['densenet121']['labels']\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(true_labels, ensemble_preds)\n",
    "    \n",
    "    # Calculate confusion matrix and classification report\n",
    "    cm = confusion_matrix(true_labels, ensemble_preds)\n",
    "    class_names = test_dataset.classes\n",
    "    report = classification_report(true_labels, ensemble_preds, target_names=class_names, output_dict=True)\n",
    "    \n",
    "    # Create result dictionary\n",
    "    result = {\n",
    "        'accuracy': accuracy,\n",
    "        'predictions': ensemble_preds,\n",
    "        'labels': true_labels,\n",
    "        'probabilities': ensemble_probs,\n",
    "        'confusion_matrix': cm,\n",
    "        'classification_report': report\n",
    "    }\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Evaluate the ensemble model\n",
    "ensemble_result = evaluate_ensemble(evaluation_results, test_dir)\n",
    "if ensemble_result is not None:\n",
    "    visualize_evaluation(ensemble_result, 'ensemble')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a2e99e",
   "metadata": {},
   "source": [
    "## Model Explanation with Grad-CAM\n",
    "\n",
    "Now, let's implement Grad-CAM for model interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c8b5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradCAM:\n",
    "    \"\"\"Class for generating Grad-CAM visualizations\"\"\"\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.hooks = []\n",
    "        \n",
    "        # Register hooks\n",
    "        self.hooks.append(self.target_layer.register_forward_hook(self.save_activation))\n",
    "        self.hooks.append(self.target_layer.register_full_backward_hook(self.save_gradient))\n",
    "        \n",
    "        self.activations = None\n",
    "        self.gradients = None\n",
    "    \n",
    "    def save_activation(self, module, input, output):\n",
    "        self.activations = output.detach()\n",
    "    \n",
    "    def save_gradient(self, module, grad_input, grad_output):\n",
    "        self.gradients = grad_output[0].detach()\n",
    "    \n",
    "    def __call__(self, x, class_idx=None):\n",
    "        # Ensure model is in evaluation mode\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Forward pass\n",
    "        x = x.to(device)\n",
    "        output = self.model(x)\n",
    "        \n",
    "        # If class_idx is None, use the class with the highest score\n",
    "        if class_idx is None:\n",
    "            class_idx = torch.argmax(output, dim=1).item()\n",
    "        \n",
    "        # Zero gradients\n",
    "        self.model.zero_grad()\n",
    "        \n",
    "        # Target for backprop\n",
    "        one_hot = torch.zeros_like(output)\n",
    "        one_hot[0, class_idx] = 1\n",
    "        \n",
    "        # Backward pass\n",
    "        output.backward(gradient=one_hot, retain_graph=True)\n",
    "        \n",
    "        # Average gradients globally\n",
    "        weights = torch.mean(self.gradients, dim=(2, 3))\n",
    "        \n",
    "        # Create weighted activation map\n",
    "        batch_size, n_channels, h, w = self.activations.size()\n",
    "        cam = torch.zeros((h, w), dtype=torch.float32, device=device)\n",
    "        \n",
    "        for i, w in enumerate(weights[0]):\n",
    "            cam += w * self.activations[0, i]\n",
    "        \n",
    "        # Apply ReLU\n",
    "        cam = torch.clamp(cam, min=0)\n",
    "        \n",
    "        # Normalize\n",
    "        if torch.max(cam) > 0:\n",
    "            cam = cam / torch.max(cam)\n",
    "        \n",
    "        # Convert to numpy and resize\n",
    "        cam = cam.cpu().numpy()\n",
    "        \n",
    "        # Remove hooks\n",
    "        for hook in self.hooks:\n",
    "            hook.remove()\n",
    "        \n",
    "        return cam\n",
    "\n",
    "def get_target_layer(model):\n",
    "    \"\"\"Get the target layer for GradCAM based on model architecture\"\"\"\n",
    "    if model.model_name == 'densenet121':\n",
    "        return model.base_model.features.denseblock4.denselayer16.conv2\n",
    "    elif model.model_name == 'resnet50' or model.model_name == 'xception':\n",
    "        # For ResNet50 and Xception (which is also ResNet50 in our implementation)\n",
    "        return model.base_model.layer4[-1].conv3\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model architecture: {model.model_name}\")\n",
    "\n",
    "def generate_gradcam(img, model):\n",
    "    \"\"\"Generate a GradCAM heatmap for the image\"\"\"\n",
    "    # Convert numpy array to tensor if needed\n",
    "    if isinstance(img, np.ndarray):\n",
    "        img = torch.from_numpy(img.transpose((2, 0, 1))).float().unsqueeze(0)\n",
    "    elif isinstance(img, torch.Tensor) and img.dim() == 3:\n",
    "        img = img.unsqueeze(0)\n",
    "    \n",
    "    # Get target layer\n",
    "    target_layer = get_target_layer(model)\n",
    "    \n",
    "    # Create GradCAM\n",
    "    grad_cam = GradCAM(model, target_layer)\n",
    "    \n",
    "    # Generate heatmap\n",
    "    heatmap = grad_cam(img)\n",
    "    \n",
    "    # Resize to match input size\n",
    "    if isinstance(img, torch.Tensor):\n",
    "        h, w = img.shape[2:]\n",
    "    else:\n",
    "        h, w = img.shape[:2]\n",
    "    \n",
    "    heatmap = cv2.resize(heatmap, (w, h))\n",
    "    \n",
    "    return heatmap\n",
    "\n",
    "def superimpose_heatmap(img, heatmap, alpha=0.6):\n",
    "    \"\"\"Superimpose a heatmap on the original image\"\"\"\n",
    "    # Convert heatmap to RGB\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "    \n",
    "    # Convert original image to uint8 if it's not already\n",
    "    if isinstance(img, torch.Tensor):\n",
    "        img = img.cpu().numpy().transpose(1, 2, 0)\n",
    "        \n",
    "        # Denormalize the image\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        img = std * img + mean\n",
    "        img = np.clip(img, 0, 1)\n",
    "        img = np.uint8(255 * img)\n",
    "    elif img.dtype != np.uint8:\n",
    "        img = np.uint8(255 * img)\n",
    "    \n",
    "    # Superimpose the heatmap on original image\n",
    "    superimposed_img = cv2.addWeighted(img, 1.0 - alpha, heatmap, alpha, 0)\n",
    "    \n",
    "    return superimposed_img\n",
    "\n",
    "def identify_affected_areas(heatmap, threshold=0.7):\n",
    "    \"\"\"Identify affected brain areas based on the heatmap\"\"\"\n",
    "    # Binarize the heatmap using the threshold\n",
    "    binary_heatmap = heatmap > threshold\n",
    "    \n",
    "    # Calculate the centroid of the affected area\n",
    "    y_indices, x_indices = np.where(binary_heatmap)\n",
    "    if len(y_indices) == 0 or len(x_indices) == 0:\n",
    "        return [\"No specific affected areas detected\"]\n",
    "    \n",
    "    centroid_y = np.mean(y_indices)\n",
    "    centroid_x = np.mean(x_indices)\n",
    "    \n",
    "    # Brain region mapping based on image quadrants\n",
    "    h, w = heatmap.shape\n",
    "    regions = []\n",
    "    \n",
    "    # Left vs Right\n",
    "    if centroid_x < w/2:\n",
    "        regions.append(\"Left hemisphere\")\n",
    "    else:\n",
    "        regions.append(\"Right hemisphere\")\n",
    "    \n",
    "    # Anterior vs Posterior\n",
    "    if centroid_y < h/2:\n",
    "        regions.append(\"Anterior region\")\n",
    "    else:\n",
    "        regions.append(\"Posterior region\")\n",
    "    \n",
    "    # Check specific quadrants for more detailed localization\n",
    "    if centroid_x < w/3:\n",
    "        if centroid_y < h/3:\n",
    "            regions.append(\"Possibly frontal lobe\")\n",
    "        elif centroid_y > 2*h/3:\n",
    "            regions.append(\"Possibly occipital lobe\")\n",
    "        else:\n",
    "            regions.append(\"Possibly temporal lobe\")\n",
    "    elif centroid_x > 2*w/3:\n",
    "        if centroid_y < h/3:\n",
    "            regions.append(\"Possibly frontal lobe\")\n",
    "        elif centroid_y > 2*h/3:\n",
    "            regions.append(\"Possibly occipital lobe\")\n",
    "        else:\n",
    "            regions.append(\"Possibly temporal lobe\")\n",
    "    else:\n",
    "        if centroid_y < h/2:\n",
    "            regions.append(\"Possibly parietal lobe\")\n",
    "        else:\n",
    "            regions.append(\"Possibly cerebellum or brain stem\")\n",
    "    \n",
    "    # Add a disclaimer\n",
    "    regions.append(\"Note: This is a preliminary estimate and should be confirmed by a medical professional\")\n",
    "    \n",
    "    return regions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adb0bc7",
   "metadata": {},
   "source": [
    "## Making Predictions with Ensemble Model\n",
    "\n",
    "Let's implement a function to make predictions with our ensemble model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97db5a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models(models_dir='models_pytorch'):\n",
    "    \"\"\"Load all trained models\"\"\"\n",
    "    models = {}\n",
    "    model_names = ['densenet121', 'resnet50', 'xception']\n",
    "    \n",
    "    for model_name in model_names:\n",
    "        model_path = os.path.join(models_dir, f\"stroke_{model_name}.pkl\")\n",
    "        if os.path.exists(model_path):\n",
    "            logger.info(f\"Loading {model_name} model from {model_path}\")\n",
    "            try:\n",
    "                with open(model_path, 'rb') as f:\n",
    "                    models[model_name] = pickle.load(f).to(device)\n",
    "                models[model_name].eval()\n",
    "                logger.info(f\"Successfully loaded {model_name} model\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error loading {model_name} model: {str(e)}\")\n",
    "    \n",
    "    if not models:\n",
    "        logger.warning(\"No models were loaded. Make sure the model files exist.\")\n",
    "    \n",
    "    return models\n",
    "\n",
    "def predict_stroke(image_path, models=None):\n",
    "    \"\"\"Predict stroke from a brain CT scan image using ensemble of models\"\"\"\n",
    "    # Load models if not provided\n",
    "    if models is None:\n",
    "        models = load_models()\n",
    "    \n",
    "    if not models:\n",
    "        raise ValueError(\"No models available for prediction\")\n",
    "    \n",
    "    # Load image\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    \n",
    "    # Preprocess image\n",
    "    transform = get_transforms(is_training=False)\n",
    "    img_tensor = transform(img).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Keep a copy of the resized image for visualization\n",
    "    img_resized = img.resize((256, 256))\n",
    "    img_array = np.array(img_resized)\n",
    "    \n",
    "    # Normalize for gradcam\n",
    "    img_normalized = transform(img).to(device)\n",
    "    \n",
    "    # Make predictions with each model\n",
    "    predictions = {}\n",
    "    for model_name, model in models.items():\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(img_tensor)\n",
    "            probs = F.softmax(outputs, dim=1)[0].cpu().numpy()\n",
    "            \n",
    "            predictions[model_name] = {\n",
    "                'normal_prob': float(probs[0]),\n",
    "                'stroke_prob': float(probs[1])\n",
    "            }\n",
    "    \n",
    "    # Calculate ensemble prediction (average of all models)\n",
    "    ensemble_normal_prob = np.mean([pred['normal_prob'] for pred in predictions.values()])\n",
    "    ensemble_stroke_prob = np.mean([pred['stroke_prob'] for pred in predictions.values()])\n",
    "    \n",
    "    # Determine the predicted class\n",
    "    predicted_class = 'Stroke' if ensemble_stroke_prob > 0.5 else 'Normal'\n",
    "    \n",
    "    # Generate heatmap for the most confident model\n",
    "    most_confident_model_name = max(\n",
    "        predictions.keys(), \n",
    "        key=lambda k: predictions[k]['stroke_prob'] if predicted_class == 'Stroke' else predictions[k]['normal_prob']\n",
    "    )\n",
    "    most_confident_model = models[most_confident_model_name]\n",
    "    \n",
    "    # Create GradCAM for visualization\n",
    "    heatmap = generate_gradcam(img_normalized, most_confident_model)\n",
    "    \n",
    "    # Create superimposed image\n",
    "    superimposed_img = superimpose_heatmap(img_array, heatmap)\n",
    "    \n",
    "    # Identify potentially affected areas\n",
    "    affected_areas = identify_affected_areas(heatmap)\n",
    "    \n",
    "    result = {\n",
    "        'predicted_class': predicted_class,\n",
    "        'confidence': float(ensemble_stroke_prob if predicted_class == 'Stroke' else ensemble_normal_prob),\n",
    "        'model_predictions': predictions,\n",
    "        'heatmap_image': superimposed_img,\n",
    "        'heatmap': heatmap,  # Raw heatmap for affected area identification\n",
    "        'affected_areas': affected_areas\n",
    "    }\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bfb3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test prediction on sample images\n",
    "def display_prediction(image_path, models=None):\n",
    "    \"\"\"Display prediction results for a single image\"\"\"\n",
    "    try:\n",
    "        result = predict_stroke(image_path, models)\n",
    "        \n",
    "        # Print prediction details\n",
    "        print(f\"Predicted class: {result['predicted_class']}\")\n",
    "        print(f\"Confidence: {result['confidence']:.4f}\")\n",
    "        \n",
    "        for model_name, pred in result['model_predictions'].items():\n",
    "            print(f\"{model_name}: Normal={pred['normal_prob']:.4f}, Stroke={pred['stroke_prob']:.4f}\")\n",
    "        \n",
    "        # Print potentially affected areas\n",
    "        print(\"\\nPotentially affected brain areas:\")\n",
    "        for area in result['affected_areas']:\n",
    "            print(f\"- {area}\")\n",
    "        \n",
    "        # Visualize the result\n",
    "        plt.figure(figsize=(18, 6))\n",
    "        \n",
    "        # Original image\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(plt.imread(image_path))\n",
    "        plt.title(\"Original Image\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # GradCAM heatmap\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(result['heatmap'], cmap='jet')\n",
    "        plt.title(\"GradCAM Heatmap\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Superimposed image\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(result['heatmap_image'])\n",
    "        plt.title(f\"Prediction: {result['predicted_class']} (Confidence: {result['confidence']:.4f})\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return result\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error predicting on {image_path}: {str(e)}\")\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Load all models\n",
    "loaded_models = load_models()\n",
    "\n",
    "# Test on sample images\n",
    "sample_paths = [\n",
    "    os.path.join(test_dir, 'Normal', '50 (10).jpg'),\n",
    "    os.path.join(test_dir, 'Stroke', '70 (33).jpg')\n",
    "]\n",
    "\n",
    "for sample_path in sample_paths:\n",
    "    if os.path.exists(sample_path):\n",
    "        print(f\"\\nPredicting on {sample_path}...\")\n",
    "        display_prediction(sample_path, loaded_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ff59f4",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This project demonstrates the use of deep learning for stroke detection from brain CT scans. We trained and evaluated three different CNN models (DenseNet121, ResNet50, and Xception) and combined them into an ensemble for improved performance.\n",
    "\n",
    "### Key Points:\n",
    "\n",
    "1. **Model Architecture**: We fine-tuned pre-trained models on our specific dataset, allowing us to benefit from transfer learning.\n",
    "   \n",
    "2. **Ensemble Approach**: By averaging predictions from multiple models, we achieved better performance than any single model.\n",
    "   \n",
    "3. **Model Interpretability**: Using Grad-CAM, we can visualize which regions of the brain influence the model's decision, providing a level of interpretability important for medical applications.\n",
    "   \n",
    "4. **Incremental Training**: The code allows for training one model at a time and saving the results, which is useful for limited computational resources.\n",
    "\n",
    "### Future Work:\n",
    "\n",
    "1. **Advanced Architectures**: Explore newer CNN architectures like EfficientNet or Vision Transformers.\n",
    "   \n",
    "2. **More Data**: Acquire and incorporate more training data to improve model robustness.\n",
    "   \n",
    "3. **Clinical Validation**: Work with medical professionals to validate model predictions on real-world cases.\n",
    "   \n",
    "4. **Stroke Type Classification**: Extend the model to classify different types of strokes (ischemic vs. hemorrhagic).\n",
    "   \n",
    "5. **Multi-modal Approach**: Combine CT scans with other data such as patient medical history for more comprehensive diagnosis.\n",
    "\n",
    "This project serves as a foundation for automated stroke detection systems that could assist radiologists in making faster and more accurate diagnoses, potentially improving patient outcomes through earlier intervention."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
